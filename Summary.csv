,Resume_Tag,Cosine Distances,Keywords,Skills,SKill_hits,Education,Experience,Experience Years
18,//nb/corp/Users/NY/NY16/sbhardwa/@nbcfg/Desktop/Python codes/PDFextract/New folder/CV\Ken_Wu-DE-HKARP.pdf,1.081054308,use year team york senior data engin iheartradio code project applic skill pipelin computing product lot ken month softwar comput scienc master net audienc payment program algorithm process new compani job execut hadoop cluster best jenkin aggreg manag gener architectur architecture user sharp busi java big teammat peopl recommend univers provid puppet web differ result huge increas societi januari pig ensur qualiti ,"['aws{2}', 'docker{0},', 'sql{0},', 'hadoop{6}', 'hive{4}', 'teradata{0},', 'scala{1}', 'kubernetes{0},', 's3{3}', 'amazon redshift{0},', 'python{6}', 'matlab{0},', 'django{0},']",22,"['State University of New York at Stony Brook', 'M.S,\xa0Computer Science,\xa02005\xa0-\xa02006', 'Activities and Societies:\xa0 Member of Stony Brook Association for Computing Machinery (A.C.M)', 'programming team, Upsilon Pi Epsilon C.S. Honor Society', 'State University of New York at Stony Brook', 'B.S,\xa0Computer Science, Applied Mathematics and Statistics,\xa02002\xa0-\xa02005', 'Activities and Societies:\xa0 Member of Stony Brook Association for Computing Machinery (A.C.M)', 'programming team, Upsilon Pi Epsilon C.S. Honor Society, Cum Laude Honor', 'Ken Wu', 'Brooklyn, New York', 'Senior Data Engineer at iHeartRadio', '2 people have recommended Ken', '""I was fortunate to work with Ken on the DataLake project at Unified and he had a consistently', 'positive impact on the successful finish of the project. While I was just freshly graduating from', 'Carnegie Mellon University with master degree in Software Engineering few years ago but not', 'much real world enterprise data pipeline experience, Ken was an accomplished technical lead with']","['Senior Data Engineer at iHeartRadio', 'January 2019 \xa0-\xa0 Present\xa0 (9 months)', '- Leading the effort to maintain and improve and expand the analytics and machine learning', 'infrastructure and data pipelines', '- Collaborating with teams of data scientists here implementing some M.L. models with the data', 'scientists here using Stochastic Gradient Descent (SGD) and Neural Networks/Deep Learning.', '- Upgrading the AirFlow 1.10.5 with python 3 on the whole infrastructure (the legacy system was on', '1.9.0 and python 2.7)', '- Won 2 hackathon programming competitions with both best-engineering award', 'Big Data/Cloud Engineer Lead at Unified', 'December 2015 \xa0-\xa0 December 2018\xa0 (3 years 1 month)', '1) Built and implemented the first-generation ETL data pipeline from raw s3 data received from', 'first data party provider and then injected to the AWS redshift using Hive and Spark (PySpark', 'DataFrame API); And for second generation, re-architected it in a data-lake on RDS version to', ""further save company's storage costs with most jobs hooked up with data quality checks to ensure"", 'data correctness.  Examples of the ETL spark jobs are to i) calculate the markov_chain problems,', ""identify all audiences's user numbers that are increasing each quarter by 10%, and ii) writing"", 'customized pyspark udf function for aggregations.', '2) Hooked up the above second generation ETL data pipeline using Jenkins DSL groovy and', 'Apache AirFlow for full automation and task schedulings/executions.', '3) Contributed to lot to their python code base: Communique and Audience Generation tools.', '4) Help data-science team to automate their existing manual long running jobs by chaining them', 'together using Jenkins Pipeline in the Jenkins environment.', 'Technical Skills:  Hive, Spark, Redshift, RDS, Apache AirFlow, Python, Pandas, Jenkins Pipeline,', 'React, redux.', 'Achievements:', ""- Won the company's 2017 Hackathon programming contest on creating a smart writing a chatbot in"", '48 hours.', '- Implemented features to support Facebook Audience Generation and developed code to support', 'iHeart 1st party data ingestion.', '- Coached and provided lot of technical guidelines and assistance to the junior members in the', 'teams who did not have computer science background.', 'Senior Big Data Architect at Qualia Media', 'August 2014 \xa0-\xa0 December 2015\xa0 (1 year 5 months)', '1) Built the ETL data pipeline along with the consumer intent signal systems on a huge hadoop/', 'spark cluster using luigi as the work-flow management tool for job scheduling/executions.  Some', 'highlights of the achievements are implementing the automatic parallelization on different data', 'topics and the pre-downloaders of remote assets off the HDFS from S3 which speeds up the daily', 'work flow by 30+ % at least.', '2) Lot of Dev ops responsibilities such as managing all the AWS EC2 nodes and making sure they', 'are mostly up and be responsive, developing puppet configuration scripts to create and provision', 'the cluster.', '3) Contributed to the Apache Pig and ElasticSearch open source community for some of the bugs I', 'found and fixed and created the pull request – such as PIG-4623.', '4) Led the entire software life-cycle including hands-on development on platform code base such as', 'Kafka-client, scala on Spark, pig scripts . . . etc, code reviews, unit-testings and integration testings', 'and deployments on Jenkins environment.', 'Technical Skills:  Big data, Spark, Hadoop, HDFS, HIVE, MapReduce, python, mesos, react and', 'circle-CI.', 'Achievements:', '- The per-down-loaders I envisioned and developed saved lot of network overhead to s3 on the', 'cluster and increased the data-locality since they are now available in the HDFS for processing.', '- I used puppet to build a Hadoop/Spark cluster on top of Mesos and it was successfully deployed', 'to production and has currently been used. The direct consequence is to save money for my', 'company for additional cluster cost for Spark since right now Spark can co-sit with Hadoop on the', 'same cluster on top of Mesos.', '- I designed an efficiently smart partitioning scheme on storing and processing the scoring-data to', 'optimize the work-flows resulting dramatic performance improvements.', 'Senior Software Engineer / Team Lead at TravelClick', 'January 2013 \xa0-\xa0 July 2014\xa0 (1 year 7 months)', 'Technical Skills:  JAVA 6 and 7, JBoss, Hadoop, HDFS, Kafka, ElasticSearch, Oracle coherent', 'cache, JMS and Fiorano MQ, Agile software development, Scrum.', 'Achievements:', '- The optimization engine that I built reduces lot of database overhead and resulted in a huge', 'performance improvement (at least 35% faster on average).', '- The live monitoring system has been widely used across the business and received a huge', 'recognition from different product teams.', '- Continuously worked on resolving the hard production issues that troubled the products and', 'reduced the JIRA tickets by 20-30% monthly on average.', '- Provided the mentor to the other new and junior developers so as to speed them up in the', 'development; Being a scrum master in a rotation basic.', '- Envisioned the needs of transforming from SVN to GIT and took a lead in the transformation and', 'being a Git master to other teammates.', 'Markit On-demand Sr. Core Java developer, A.V.P. at Markit', 'October 2009 \xa0-\xa0 January 2013\xa0 (3 years 4 months)', 'distributed Java EJB system, multi-threaded systems, server side programming, java GWT and', 'Web developments', 'Senior Software Developer at Western Union', 'March 2007 \xa0-\xa0 October 2009\xa0 (2 years 8 months)', 'Primary project was 1) an online payment service applications in C#, which was a high profile', 'payments processing', 'application: maintained and enhanced the server side and the middle layer library codes that were', 'shared across', 'different systems; developed business logic implementation handle a mix of change of business', 'requirement. 2) An event-', 'driven GUI web applications using ASP.NET for the world-wide external users: developed original', 'payment website in', 'highly MVC architecture, encompassing design, coding, testing, and maintenance; worked with', 'project managers to', 'specify, design and execute business application projects; reviewed code produced by other', 'teammates and ensures high', 'code quality; mentored peers on the team who were less familiar with the .net language and web', 'developments. Provided', 'architecture level of planning on upgrading of their .NET legacy systems from 2.0 to 3.5', 'Software developer at CCSI - Contemporary Computer Services, Inc.', 'May 2006 \xa0-\xa0 March 2007\xa0 (11 months)', 'ASP.net, database programming']",Not Found
15,//nb/corp/Users/NY/NY16/sbhardwa/@nbcfg/Desktop/Python codes/PDFextract/New folder/CV\Jayesh_Masurkar.pdf,1.066828333,developer develop administr sharepoint data engin script use requir administrator work experi month hive perform server year involv creat web hadoop big onsit microsoft master tabl packag site page map reduc program differ senior servic excel analyt team compani tool environ content document manag viewer extract technolog phase ,"['aws{0},', 'docker{0},', 'sql{7}', 'hadoop{7}', 'hive{11}', 'teradata{0},', 'scala{3}', 'kubernetes{0},', 's3{0},', 'amazon redshift{0},', 'python{1}', 'matlab{0},', 'django{0},']",29,"['•  Master’s Degree in Information Technology 2011. University of Central Missouri', '•  Bachelor’s Degree in Computer Science 2009. University of Mumbai']",['•  Banking and e-commerce domain experience.'],Not Found
20,//nb/corp/Users/NY/NY16/sbhardwa/@nbcfg/Desktop/Python codes/PDFextract/New folder/CV\Marshall_Zobel-Hadoop-DE.pdf,1.065106124,marshal fullstack academi code softwar engin william student help data project relat role financi servic year client month fellow depend model control peopl react risk need manag ani sens august ,"['aws{0},', 'docker{0},', 'sql{0},', 'hadoop{0},', 'hive{0},', 'teradata{0},', 'scala{0},', 'kubernetes{0},', 's3{0},', 'amazon redshift{0},', 'python{1}', 'matlab{0},', 'django{0},']",1,"['Fullstack Academy of Code', 'Fullstack Web Development,\xa0JavaScript,\xa02018\xa0-\xa02018', 'William & Mary', 'Bachelor of Business Administration,\xa02012\xa0-\xa02015', 'University of St. Andrews', 'Study Abroad Semester - Spring 2013,\xa02013\xa0-\xa02013', 'Marshall Zobel', 'Greater New York City Area', 'Software Engineer at Simon Data', '3 people have recommended Marshall', '""Marshall and I met as students at Fullstack Academy in early 2018, and we both went onto', 'become teaching fellows after graduating. If Marshall is not an actual superhero, then he is at the', ""very least one of the most well-rounded and dependable folks that I've ever worked with - a true"", 'professional role model. If something needed to be done, or an issue needed to be addressed,', 'then Marshall would often be the one to step up. He also has a great sense of humor and down-to-', 'earth vibe - our day-to-day interactions at Fullstack are high on my list of things I miss most about']","['Data Engineer at Simon Data', 'October 2018 \xa0-\xa0 Present\xa0 (1 year)', 'Teaching Fellow & Software Engineer at Fullstack Academy of Code', 'June 2018 \xa0-\xa0 August 2018\xa0 (3 months)', '• Mentored over 50 Fullstack Academy students and helped teach engineering concepts,', 'algorithms, debugging strategies, and code hygiene through workshops, long-term projects, and', 'code reviews.', '• Contributed production code to Fullstack Academy’s dedicated teaching platform, performing', 'Angular-to-React conversions, feature enhancements, and bug fixes.', '• Administered technical interviews for prospective students in JavaScript and Python.', 'Experienced Advisory Associate at PwC', 'November 2016 \xa0-\xa0 February 2018\xa0 (1 year 4 months)', 'Provided financial and risk management support services to federal clients, conducting A-123', ""assessments to test the effectiveness of clients' internal controls and mitigate future control risk."", 'Risk Advisory Associate at Grant Thornton LLP', 'August 2015 \xa0-\xa0 October 2016\xa0 (1 year 3 months)', 'Provided risk management and compliance services related to the Sarbanes-Oxley Act for publicly-', 'traded clients spanning a variety of industries, including pharmaceuticals, hospitality/real estate,', 'and telecommunications.', 'Convocation Speaker at William & Mary', 'August 2013 \xa0-\xa0 August 2013', ""Delivered the Convocation welcome speech to William and Mary's incoming Class of 2017, a crowd"", 'of about 1,500 students and their families.']",5
26,//nb/corp/Users/NY/NY16/sbhardwa/@nbcfg/Desktop/Python codes/PDFextract/New folder/CV\Prithvi_Deivasigamani-Hadoop-DE.pdf,1.060394559,data engin test use work creat qualiti engineer hadoop databas team scenario scienc integr perform project creation involv prithvi user fidel month complet cloud year applic case septemb person technolog agre custom valid familiar etl retail ,"['aws{7}', 'docker{0},', 'sql{5}', 'hadoop{12}', 'hive{2}', 'teradata{0},', 'scala{0},', 'kubernetes{0},', 's3{2}', 'amazon redshift{0},', 'python{0},', 'matlab{0},', 'django{0},']",28,"['University of North Carolina at Charlotte', 'Master of Science,\xa0Computer Science,\xa02009\xa0-\xa02011', 'Anna University', 'Bachelor of Technology,\xa0Information Technology,\xa02006', 'Prithvi Deivasigamani', 'Jersey City, New Jersey', 'Data Engineer | Big Data | Hadoop | AWS Cloud', '1 person has recommended Prithvi', '""Prithvi was a part of our data quality assurance team. He was always willing to put in the time', 'to complete work and meet deadlines. He could work well independently and his agreeable', 'personality allowed him to work well in teams. He unhesitatingly agreed to present and train', 'coworkers on new software. Pritvi was a pleasure to have on the team!""', '—Lisa Batts,\xa0Professional Development Coach,\xa0 Capital Coaching, LLC,\xa0 managed Prithvi at', 'Fidelity Investments']","['Assistant Vice President (Data Science) at MUFG', 'September 2019 \xa0-\xa0 Present\xa0 (1 month)', 'Senior Data Engineer- AWS/Hadoop (Consultant) at Vanguard', 'November 2017 \xa0-\xa0 August 2019\xa0 (1 year 10 months)', 'Principal Associate/Data Engineer at Capital One', 'August 2015 \xa0-\xa0 October 2017\xa0 (2 years 3 months)', 'I work as an Agile team member with the Retail Bank performing the role of Data Engineer in', 'Hadoop and Cloud.', '• Involved in the development and testing of data pipeline using Hive, Pig, JAVA UDF and Bash for', 'ETL in Hadoop data lake', '• Analyzed source data from vendors in Hadoop data lake for Data Quality issues', '• Migration of data from Hadoop data lake (Batch system) to AWS Cloud (Event Driven', 'Architecture)', '• Automated the deployment of DB objects in Amazon RDS', '• Created AWS lambdas and schedule using CloudWatch Triggers to support the infrastructure', 'needs', '• Created a framework for File archival in S3 and Data Cleanup in AWS RDS using CFT, EC2, S3,', 'Lambda, Shell and PostgresSQL', '• Created Jenkins jobs for CI/CD using git, Maven and Bash scripting', '• Built regression test suite in CI/CD pipeline with Data setup, test case execution and tear down', 'using Cucumber- Gherkin, Java, Spring DAO, PostgreSQL', '• Automated data testing in Hadoop and Cloud', 'Data Engineer (Test/ETL/Hadoop) at Fidelity Investments', 'July 2011 \xa0-\xa0 July 2015\xa0 (4 years 1 month)']",8
12,//nb/corp/Users/NY/NY16/sbhardwa/@nbcfg/Desktop/Python codes/PDFextract/New folder/CV\Giovanni_De_Marinis.pdf,1.058331471,year month data engin intellig oracl model qualiti gvdmar ,"['aws{0},', 'docker{0},', 'sql{0},', 'hadoop{0},', 'hive{0},', 'teradata{0},', 'scala{0},', 'kubernetes{0},', 's3{0},', 'amazon redshift{0},', 'python{0},', 'matlab{0},', 'django{0},']",0,"['Global Big Data Conference', 'Big Data Boot Camp, NYC,\xa0Big Data,\xa02013\xa0-\xa02013', 'SAS Institute Inc.', 'SAS Masterclass,\xa02009\xa0-\xa02009', 'Oracle Corp.', 'Oracle BI Campus,\xa02008\xa0-\xa02008', 'Politecnico di Bari', ""Master's Degree in Computer Engineering,\xa0Computer Engineering,\xa02007"", 'Giovanni De Marinis', 'Greater New York City Area', 'Data Engineer']","['Sr. Data Engineer at HBO (Warnermedia) at AT&T', 'September 2018 \xa0-\xa0 Present\xa0 (1 year 1 month)', 'Data Engineer, Decision Sciences at UM Worldwide', 'April 2017 \xa0-\xa0 August 2018\xa0 (1 year 5 months)', 'Senior Business Intelligence Analyst at UM Worldwide', 'October 2014 \xa0-\xa0 March 2017\xa0 (2 years 6 months)', 'Business Intelligence Analyst at Fordham University', 'June 2012 \xa0-\xa0 September 2014\xa0 (2 years 4 months)', 'Business Intelligence Consultant at Beta80 Group', 'July 2010 \xa0-\xa0 June 2011\xa0 (1 year)', 'Business Intelligence Consultant at SAS', 'January 2009 \xa0-\xa0 July 2010\xa0 (1 year 7 months)', 'Business Intelligence Intern at Oracle', 'January 2008 \xa0-\xa0 January 2009\xa0 (1 year 1 month)']",10
24,//nb/corp/Users/NY/NY16/sbhardwa/@nbcfg/Desktop/Python codes/PDFextract/New folder/CV\NILANJAN_CHATTERJEE-HKARP.pdf,1.058029287,use data scientist model analyt work test team engin process integr managing manag science scienc script python sql predict year experi featur queri hadoop job strategi ani complex dashboard report tableau spark degre code defin advanc month dag compos updat insight mobil server hive set devic sale sales cluster skill cogniz addit visual docker pilot applic societi design oozi usag hewlett cloud ,"['aws{7}', 'docker{4}', 'sql{12}', 'hadoop{6}', 'hive{6}', 'teradata{0},', 'scala{1}', 'kubernetes{1}', 's3{5}', 'amazon redshift{0},', 'python{14}', 'matlab{0},', 'django{0},']",56,"['University of North Carolina at Charlotte', 'Master’s Degree,\xa0Computer Science,\xa02016\xa0-\xa02017', 'Activities and Societies:\xa0 Triveni Intramural Sports', 'NARULA INSTITUTE OF TECHNOLOGY', ""Bachelor's Degree,\xa0Electrical, Electronics and Communications Engineering,\xa02009\xa0-\xa02013"", 'Activities and Societies:\xa0 IEEE', 'VIVEKANANDA MISSION SCHOOL', 'ISC,\xa0Physical Sciences,\xa02007\xa0-\xa02009', 'Activities and Societies:\xa0 SPICMACAY', 'NILANJAN CHATTERJEE', 'Germantown, Maryland', 'Data Scientist @ Hughes |H1B| DS | ML| AI | Deep Learning| Python| R | SQL| Hadoop |', 'Spark| Kafka| Recommendation | CD', 'arkasuperstar@gmail.com - +1 704-345-9929', '1 person has recommended NILANJAN', '""Nilanjan is calm and composed. He is extremely detail oriented and analytical. He is meticulous', 'learner. This makes a sought-after resource for any complex piece of project.He would definitely', 'make a great addition to any team engaged in complex software development.""', '—Shubhodaye H G,\xa0Test Engineer,\xa0 Infogain,\xa0 managed NILANJAN indirectly at Hewlett Packard', 'Enterprise']","['technologies like SQL Server, SSIS,, SSMS, Toad, Unix, Putty', 'Programmer Analyst at Cognizant', 'July 2013 \xa0-\xa0 September 2014\xa0 (1 year 3 months)', '• Multi-channel attribution analysis as per given dataset from clients and analysing using available', 'toolkits like Looker and Google Analytics integration with QVD.', '• Have worked on Docker, Vagrant, Nginx, Jenkins, Git , UrbanCode ,Bugzilla, Ansible, Chef, JIRA,', 'Microsoft TFS for project deliverables.', '• Created and deployed MSI and virtual applications using SCCM 2012 , Landesk and Altiris .', 'Customized Mobile Device Management and BYOD implementation using Air Watch,', 'Intune, and Mobile Iron.', '• Quality Analyst and Deployment Lead for Application Packaging  and Deployment , OSD Imaging,', 'Patch management using SCCM 2007/2012/Altris/LanDesk/Marimba with hands-on scripting using', 'VBScript,Powershell, Bash, Python, Perl.']",7
17,//nb/corp/Users/NY/NY16/sbhardwa/@nbcfg/Desktop/Python codes/PDFextract/New folder/CV\Josh_Tennefoss.pdf,1.056893643,engin right month data mathemat novemb year ,"['aws{0},', 'docker{0},', 'sql{0},', 'hadoop{0},', 'hive{0},', 'teradata{0},', 'scala{0},', 'kubernetes{0},', 's3{0},', 'amazon redshift{0},', 'python{0},', 'matlab{0},', 'django{0},']",0,"['Stanford University', 'MS Computational and Mathematical Engineering, MS MS&E,\xa02013\xa0-\xa02015', 'University of Southern California', 'BA Mathematics, BS Kinesiology,\xa02007\xa0-\xa02012', 'Josh Tennefoss', 'New York, New York', 'Data Scientist and Engineer']","['Garden Leave at Non Compete', 'November 2018 \xa0-\xa0 Present\xa0 (11 months)', 'Manager, Research Data and Analytics Technology at Citadel LLC', 'May 2017 \xa0-\xa0 November 2018\xa0 (1 year 7 months)', 'Research Data Engineer at Citadel LLC', 'November 2015 \xa0-\xa0 May 2017\xa0 (1 year 7 months)', 'Lead Data Scientist at Planet Labs', 'September 2014 \xa0-\xa0 October 2015\xa0 (1 year 2 months)', 'Grad Student at Stanford University', 'August 2013 \xa0-\xa0 June 2015\xa0 (1 year 11 months)', 'MS: Computational and Mathematical Engineering', 'MS: Management, Science and Engineering']",5
13,//nb/corp/Users/NY/NY16/sbhardwa/@nbcfg/Desktop/Python codes/PDFextract/New folder/CV\Huang_P-DE-HKARP.pdf,1.056835927,senior data engin design wireless chip year manag month tool process work trade new technolog huang web project univers digit analysi roofstock asic level test code network infrastructur entir compani use api algorithm technic bitcoin high model product firm person rfmd base time qualiti creat softwar improv interfac research pan filter program financ financi python blockchain lab languag june methodolog startup gener real estat phi analyt strong experi statist initi quickli modul airflow famili sql result stanford field quantit frequenc structur float problem directli sourc januari matlab graphic select excel servic databas professor fpga start variou snowflak quant team place anderson ,"['aws{6}', 'docker{2}', 'sql{5}', 'hadoop{1}', 'hive{1}', 'teradata{0},', 'scala{4}', 'kubernetes{0},', 's3{3}', 'amazon redshift{0},', 'python{8}', 'matlab{4}', 'django{0},']",34,"['Blockchain University', 'Certificate of Completion,\xa0Learned how to program on the Bitcoin & Ethereum Blockchains Jan-Feb', '2015,\xa02015\xa0-\xa02015', 'University of California, Los Angeles - The Anderson School of Management', 'Master of Financial Engineering (MFE),\xa0Quantitative Finance,\xa02011\xa0-\xa02011', 'Beijing Language and Culture University', 'Intensive Language Program,\xa02005\xa0-\xa02006', 'Stanford University', 'Master of Science (MS),\xa0Electrical Engineering,\xa01998\xa0-\xa02000', 'University of California, Berkeley', 'Bachelor of Science (BS),\xa0Electrical Engineering and Computer Science,\xa01992\xa0-\xa01995', 'Saratoga High', 'High School,\xa0GD,\xa01988\xa0-\xa01992', 'Huang P.', 'Oakland, California', 'Senior Data Engineer at Juvo', '4 people have recommended Huang', '""Huang has good digital design qualities. He makes sure that he comprehend the specification', 'completely to the smallest details and delivers high quality RTL code, doing thorough verification.', 'Huang understands very well ASIC design flow steps and all aspects of methodology as well tools', 'used in ASIC design and uses them efficiently. During our work at RFMD Huang quickly gained']","['—Dmitry Cherniavsky,\xa0Advanced architectures, algorithms and standards,\xa0 SiBEAM technology', 'group Silicon Image/Lattice Semiconductor,\xa0 worked directly with Huang at Pan Filter Technology', '""Huang worked for me as a senior ASIC design engineer at Iospan Wireless. He was a key', ""designer on Iospan's MIMO PHY ASIC. He is very meticulous, always enthusiastic and a pleasure"", 'to work with!""', '—Joanne Ottney,\xa0Vice President Engineering,\xa0 Palo Alto Networks,\xa0 managed Huang at Iospan', 'Wireless', '""Huang is a dependable and resourceful colleague. He\'s able to solve complicated problems and', 'articulate his solution elegantly. His latest creation, Pan Filter, is a unique solution to improve audio', 'video quality. I highly recommend Huang.""', '—Jim Nguyen,\xa0VP of Products & Marketing,\xa0 OKCoin,\xa0 was with another company when working', 'with Huang at Pan Filter Technology', '""I shared three years of intense work with Huang at RFMD/Resonext developing the physical layer', 'for a wireless networking solution. Among the different tasks that Huang worked on, I remember', 'Huang implementing the digital section of a high speed host interface and later validating it in', 'the lab. The module worked flawlessly and initial difficulties were quickly resolved thanks to his', 'dedication and smart thinking. His open personality and constant good temper makes him an', 'excellent person to interact and work with on a daily basis.""', '—Andrea R.,\xa0R&D Engineer,\xa0 ABB,\xa0 worked directly with Huang at Pan Filter Technology']",Not Found
30,//nb/corp/Users/NY/NY16/sbhardwa/@nbcfg/Desktop/Python codes/PDFextract/New folder/CV\Shivakrishna_Bade-HKARP.pdf,1.055654623,data engin busi use analyt scienc science report product databas cloud oracl technolog activ schema creat analysi year experi load job server sourc design excel hdf dimension model india etl custom tableau hdfs hive python volunt expert function educ missouri labor child warehous view process tool ,"['aws{3}', 'docker{0},', 'sql{6}', 'hadoop{6}', 'hive{10}', 'teradata{0},', 'scala{3}', 'kubernetes{0},', 's3{1}', 'amazon redshift{0},', 'python{10}', 'matlab{0},', 'django{0},']",39,"['of child rights and against child labor', 'Shivakrishna Bade', 'Greater St. Louis Area', 'Data Engineer | BigData | AWS | GCP | ETL | Python | Airflow | Hadoop | Hive | Spark | Scala', '| SQL | Analytics | Tableau', 'sb7f9@mst.edu - +1 573-202-0962']","['• Built & deployed dashboard using SAP Business Objects for market analysis of customers', '• Learnt and dealt with important principles of Project Management', 'BI/DW Developer - Data Engineer at Jio', 'June 2012 \xa0-\xa0 July 2014\xa0 (2 years 2 months)', '• Extract raw data from customer applications load into Hadoop HDFS/ Hive', '• Apply business rules and transform, build data pipelines to load into Hive/Impala Data lake', '• Use ODI/Airflow framework ETL data pipelines jobs creation, scheduling, administration', '• Real-time data ingestion using Spark streaming, Kafka and golden gate into HDFS, Hive', '• Create datasets for Business Intelligence, Data Science, Analytics and Custom reports', '• Create Tableau datasources, live connections, automate extract schedules, user access', '• Developed Business Intelligence reports, dashboards, KPIs in Tableau with multi datasources', '• Creating schemas, users, user roles, groups administering Oracle Data Warehouse access', '• Expert with BigData toolset Hadoop, MapReduce, Pig, Hive, Impala, Spark, Python', '• Automate and Deploy Data Science models into production, applications, Identify metrics', '• Expert in Dev-Ops architecture, Linux and Windows servers , Bash, Shell scripting']",2
9,//nb/corp/Users/NY/NY16/sbhardwa/@nbcfg/Desktop/Python codes/PDFextract/New folder/CV\Darwin_Yip.pdf,1.050305501,data month servic support creat server student secur applic procedur univers comput new york process integr work gener dynam softwar model migrat custom event sql api environ analyt program web solut technic team experi siebel email intern report obie script autom machin databas manag fund august crm studi acceler transit particip android basic load queri administr yipdarwin septemb replac orchestra level repositori order time network perform handl json content msi rest sourc user request ,"['aws{3}', 'docker{1}', 'sql{10}', 'hadoop{0},', 'hive{0},', 'teradata{0},', 'scala{1}', 'kubernetes{0},', 's3{3}', 'amazon redshift{0},', 'python{8}', 'matlab{0},', 'django{0},']",26,"['Coursera: Machine Learning (Andrew Ng) (2015)', 'New York University', 'Cyber Security, Master of Science (June 2014)', 'University at Buﬀalo', 'Computer Engineering, Bachelor of Science (May 2012)', 'Mathematics, Bachelor of Arts (May 2012)', '1']",[],Not Found
11,//nb/corp/Users/NY/NY16/sbhardwa/@nbcfg/Desktop/Python codes/PDFextract/New folder/CV\Ed_Kurowski.pdf,1.043385196,data engin spotifi year month applic work softwar new mcgraw use experi april focus integr process ,"['aws{0},', 'docker{0},', 'sql{2}', 'hadoop{1}', 'hive{1}', 'teradata{0},', 'scala{0},', 'kubernetes{0},', 's3{1}', 'amazon redshift{0},', 'python{2}', 'matlab{0},', 'django{0},']",7,"['Ferrum College', 'BS,\xa0Computer Science,\xa02002\xa0-\xa02005', 'Ed Kurowski', 'Greater New York City Area', 'Data Engineer at Spotify']","['Data Engineer at Spotify', 'June 2017 \xa0-\xa0 Present\xa0 (2 years 4 months)', 'Senior Software Engineer at Collective', 'November 2016 \xa0-\xa0 April 2017\xa0 (6 months)', 'Software Engineer at Docurated', 'October 2015 \xa0-\xa0 October 2016\xa0 (1 year 1 month)', 'Data Engineer at Integral Ad Science', 'November 2014 \xa0-\xa0 September 2015\xa0 (11 months)', 'Senior Software Engineer at Nomi', 'April 2014 \xa0-\xa0 November 2014\xa0 (8 months)', 'Senior Software Engineer at Ghostery, Inc.', 'April 2013 \xa0-\xa0 April 2014\xa0 (1 year 1 month)', 'Senior Software Engineer at Wireless Generation', 'January 2012 \xa0-\xa0 April 2013\xa0 (1 year 4 months)', 'Senior Developer at Metrics3, LLC', 'July 2011 \xa0-\xa0 January 2012\xa0 (7 months)', 'Consulting at Showtime.  Working on Java/Spring applications running on JBoss and Tomcat.', 'Currently creating a new application that leverages Apache Camel for enterprise integration.']",6
14,//nb/corp/Users/NY/NY16/sbhardwa/@nbcfg/Desktop/Python codes/PDFextract/New folder/CV\Jacob_Trunsky.pdf,1.041709702,month data insight ventur conduct team includ research analyst bonobo experi market washington new york usa vogu focus corpor stakehold ,"['aws{0},', 'docker{0},', 'sql{0},', 'hadoop{0},', 'hive{0},', 'teradata{0},', 'scala{0},', 'kubernetes{0},', 's3{0},', 'amazon redshift{0},', 'python{0},', 'matlab{0},', 'django{0},']",0,"['Washington University in St. Louis', 'BSBA,\xa0Economics,\xa02010\xa0-\xa02014', 'Jacob Trunsky', 'New York, New York', 'Data Engineer @ Away']","['Data Engineer at Away', 'January 2019 \xa0-\xa0 Present\xa0 (9 months)', 'Away (awaytravel.com) is modernizing the travel experience, beginning with your luggage, while', 'striving to set the example for how socially conscious companies should conduct themselves. In', 'November 2015, we launched our brand in Vogue, GQ, and USA Today, and have been featured']",4
21,//nb/corp/Users/NY/NY16/sbhardwa/@nbcfg/Desktop/Python codes/PDFextract/New folder/CV\Mourya_Abbareddy.pdf,1.041482344,month york scienc data intern analyst secur year ,"['aws{0},', 'docker{0},', 'sql{0},', 'hadoop{0},', 'hive{0},', 'teradata{0},', 'scala{0},', 'kubernetes{0},', 's3{0},', 'amazon redshift{0},', 'python{0},', 'matlab{0},', 'django{0},']",0,"['Georgia Institute of Technology', ""Master's degree,\xa0Computer Science,\xa02018\xa0-\xa02020"", 'Virginia Commonwealth University', 'B.S,\xa0Computer Science, Economics,\xa02009\xa0-\xa02013', 'Godwin High School', 'High School,\xa02005\xa0-\xa02009', 'Mourya Abbareddy', 'New York, New York', 'Data Engineer at TIDAL']","['Data Engineer at TIDAL', 'May 2019 \xa0-\xa0 Present\xa0 (5 months)', 'Data Analytics Associate at JPMorgan Chase & Co.', 'May 2016 \xa0-\xa0 May 2019\xa0 (3 years 1 month)', 'Technology Analyst at Wells Fargo Securities', 'June 2014 \xa0-\xa0 May 2016\xa0 (2 years)', 'Business Intelligence Analyst at Markel Corporation', 'October 2013 \xa0-\xa0 March 2014\xa0 (6 months)', 'Cyber Security Intern at DuPont', 'July 2013 \xa0-\xa0 September 2013\xa0 (3 months)', 'Software Engineering Intern at Timmons Group', 'May 2012 \xa0-\xa0 June 2013\xa0 (1 year 2 months)']",7
16,//nb/corp/Users/NY/NY16/sbhardwa/@nbcfg/Desktop/Python codes/PDFextract/New folder/CV\Jessica_R.pdf,1.038568988,data engin develop developer team product manag month process analysi work manager intern includ report portal spicework servic softwar train autom improv research maintain user sourc enabl jessica project cours educ requir pain new test drive school passion love outcom creat instructor scienc time decad recent custom ,"['aws{0},', 'docker{0},', 'sql{3}', 'hadoop{0},', 'hive{0},', 'teradata{0},', 'scala{0},', 'kubernetes{0},', 's3{0},', 'amazon redshift{0},', 'python{2}', 'matlab{0},', 'django{0},']",5,"['The University of Texas at Austin', 'Bachelor of Science (BS),\xa0Computer Science,\xa02006\xa0-\xa02010', 'Jessica R.', 'Greater New York City Area', 'Data Engineer', '1 person has recommended Jessica', '""I\'ve known Jessica for the better part of this decade and during that time had the privilege to see', 'her grow professionally. Ever since we first met, I was impressed by her passion towards any']","['Product Manager at Tidelift', 'February 2019 \xa0-\xa0 June 2019\xa0 (5 months)', 'Working with a great team to help make open source software better for everyone by paying the', 'maintainers and enabling development teams relying on open source software to sleep better at', 'night.', '- User research, journeys and onboarding']",0
29,//nb/corp/Users/NY/NY16/sbhardwa/@nbcfg/Desktop/Python codes/PDFextract/New folder/CV\Sandish_Kumar_H_N-DE--HKARP.pdf,1.038461041,use big data solut engin hbase technolog platform hive certifi hadoop spark design analyt time base event stream search program respons cluster user mapreduc sourc work build manag databas busi sandish store custom storm kafka web servic node java queri file restful analysi project differ client amazon hdf gener sequenc rest api softwar perform color process cassandra month truck model year set languag input sql track load produc imag http includ focu cloud machin format knowledg kudu bioscienc clean cleans activ ignit learn relev david tool map index densiti environ end qualiti dec recommend product validation valid new open threat script streamset ,"['aws{4}', 'docker{4}', 'sql{20}', 'hadoop{56}', 'hive{30}', 'teradata{0},', 'scala{11}', 'kubernetes{1}', 's3{17}', 'amazon redshift{0},', 'python{3}', 'matlab{0},', 'django{0},']",146,"['Visvesvaraya Technological University', ""Bachelor's Engineering,\xa0Computer Science,\xa02008\xa0-\xa02011"", 'School of Mines', 'Diploma in Computer Science,\xa0Computer Science,\xa02005\xa0-\xa02008', 'Activities and Societies:\xa0 ISQLProject Internet Structure query language', 'Sandish Kumar H N', 'Greater Minneapolis-St. Paul Area', 'Big Data Solutions Engineer at phData', 'sandishsany@rediffmail.com - 9008990742', '4 people have recommended Sandish Kumar', '""Sandish is one of the most talented big data software engineers I have ever met. He worked his', 'way up from the bottom and has acquired an amazing set of data wrangling, data cleaning and', 'filtering and end to end big data machine learning pipelines. I highly recommend Sandish and', 'would hire him again in a second!""', '—David Johnston,\xa0Sr AI/ML Cloud Architect,\xa0 Wipro Limited,\xa0 managed Sandish Kumar at The', 'Apache Software Foundation', '""Good,hardworker""', '—Rajesh D S,\xa0Senior Associate (BigData),\xa0 Cognizant Technology Solutions,\xa0 managed Sandish', 'Kumar indirectly at PointCross']","['EC2 script.', 'Implemented D3.js and Tableau charts to show performance difference between', 'Apache                         Ignite and Apache Spark.', 'Environment: Spark, Spark Core, Data Frame’s, Spark Streaming, Scala, HDFS, Apache Ignite, Yardstick Tool,', 'D3js, Tableau, AWS, 10 million twitter data records and 1 billion auto generated records.', 'Project Name: E-Commerce Data Pipeline', 'Client: Obsessory.com', 'Project Description: Obsessory is a technology company that provides a web and mobile platform to assist', 'shoppers in  discovery, search, comparison, and tracking of items across the Internet. Obsessory’s powerful', 'search  engine  catalogs  millions  of  products  from  online  stores  on  a  daily  basis  and  uses  proprietary', 'algorithms to enhance the depth and  breadth of the user’s search.  Obsessory employs adaptive and social', 'learning to continuously refine the search results and present the user  with the most  relevant selection of', 'items. Furthermore, Obsessory helps users keep track of desired items across the Internet and get notified of', 'price changes, and availability of tracked items as well as sales, store events and promotions Responsibilities:', 'Pre-Processing:', 'Crawling of 100+ sites Data using Nutch', 'Fashion based ontology maintenance', 'Using Scala, Spark & echo system to enriched given data using Fashion Ontology to', 'Validation/Normalizing the data', 'Designed schema and modeling of data and Written algorithm to store all validated', 'data in Cassandra using Spring Data Cassandra REST', 'Programs for Validation/Normalizing/Enriching and REST API to Develop UI Based on', 'manual QA Validation. Used SparkSQL, Scala to running QA based SQL queries.', 'Indexing:', 'MR Programs on top of Hbase:', '•', '•', '•', '•', '•', '•', 'To standardize the Input Merchants data', 'To upload images to RackSpace CDN', 'To index the given Data sets into HSearch', 'To  MR  programs  on  Hbase  to  extract  the  color  information  from  Images', 'including density.', 'To MR programs on Hbase to persist the data on Hbase tables', 'above MR jobs will run based on timing and bucketing. Color-Obsessed:', 'Using  Image  color  and  density  data  Users  are  allowed  to  select  1,2..  colors  with  different', 'densities  and  result  will  be  a  list  of  products  where  each  product  image  contains  all  give', 'colors  with  exact  density  this  has  been  implemented  on  top  Hbase  using  Spring  REST  web', 'service for color Obsessed search API.', 'Post-Processing:', 'Setting up the Spark Streaming and Kafka Cluster', 'Developed a Spark Streaming Kafka App to Process Hadoop Jobs Logs', 'Kafka Producer to send all slaves logs to Spark Streaming App', 'Spark  Streaming  App  to  Process  the  Logs  with  given  rules  and  produce  the  Bad', 'Images, Bad records, Missed Records etc.', 'Spark Streaming App collect user actions data from front end', 'Kafka  Producer  based  Rest  API  to  collect  user  events  and  send  to  Spark  Streaming', 'App', 'Hive  Queries  to  Generate  Stock  Alerts,  Price  Alerts,  Popular  Products  Alerts,  New', 'Arrivals for each user based on given likes, favorite, shares count information', 'Worked  on  SparkML  library  for  Recommendations,  Coupons  Recommendations,', 'Rules Engine.', 'Environment:  HSearch  (Hbase+lucene),  Cassandra,  Hive,  Spark  (Core,  SQL,  ML,  Streaming),  Hadoop,', 'MapReduce,  Amazon  Webservice,  Linode,  CDN,  Scala,  Java,  Affiliates  feeds  Rakuten,  CJ,  Affiliate  window,', 'Webgains.', 'Project Name: Cimbal/MobApp Pay', 'Client: Intel', 'Project Description: Cimbal is a mobile promotion and payment network designed to increase business sales', 'and deliver targeted deals to consumers Responsibilities:', '•  Written MapReduce programs to validate the data', ""•  Written more than 50 Spring Data Hbase rest API's in Java"", '•', '•  Written Hive queries for analytics on user’s data.', 'Schema design on Hbase and cleaning data', 'Environment: Hadoop MapReduce, Hbase, Spring Data Rest Web Service, CDH, Users Payment Data', 'Project Name: Truck Events Analysis', 'Client: HortonWorks', 'Project Description: The Trucking business is a high-risk business in which truck drivers venture into remote', 'areas,  often  in  harsh  weather  conditions  and  chaotic traffic  on  a  daily  basis.  Using  this  solution  illustrating', 'Modern Data Architecture with Hortonworks Data Platform, we have developed a centralized management', 'system that can help reduce risk and lower the total cost of operations.', 'Responsibilities:', '•  Written a simulator to send/emit events based on NYC DOT data file.', '•  Written Kafka Producer to accept/send events to Kafka Producer which is on Storm Spout', '•  Written Storm topology to accept events from Kafka Producer and Process Events', '•  Written Storm Bolt to Emit data into Hbase, HDFS, Rabbit-MQ Web Stomp', '•  Hive Queries to Map Truck Events Data, Weather Data, Traffic Data', 'Environment:  Hadoop,  HDFS,  Hive,  HBase,  Kafka,  Storm,  Rabbit-MQ  WebStormp,  Google  Maps,  New  York', 'City Truck Routes from NYC DOT. -Truck Events Data generated using a custom', 'simulator.  -  Weather  Data,  collected  using  APIs  from  Forcast.io.  -Traffic  Data,  collected  using  APIs  from', 'MapQuest.', 'Project Name: Comparative Analysis of Big Data Analytical Tools – (Hive, Hive on Tez,', 'Impala, SparkQL, Apache Drill, BigQuery, PrestoDB running on the Google Cloud and', 'AWS)', 'Client: ThirdEyeCss.com Responsibilities:', '•', '•', 'Installation  of  Hive,  Hive  on  Tez,  Impala,  SparkQL,  Apache  Drill,  BigQuery,  PrestoDB,  Hadoop,', 'Cloudera CDH, Hortonworks HDP', 'Schema  design  for  data  sets  on  all  Hive,  Hive  on  Tez,  Impala,  SparkQL,  Apache  Drill,  BigQuery,', 'PrestoDB', '•  Query design for given data set', '•  Debugging  on  Hive,  Hive  on  Tez,  Impala,  SparkQL,  Apache  Drill,  BigQuery,  PrestoDB,  Hadoop,', 'Cloudera CDH, Hortonworks HDP', 'Time Comparison of each Hive, Hive on Tez, Impala, SparkQL, Apache Drill, BigQuery, PrestoDB', 'Time comparison between different cloud platforms', 'Times metrics web based visualization design on google charts', '•', '•', '•', 'Environment: Hive, Hive on Tez, Impala, SparkSQL, Apache Drill, BigQuery, PrestoDB,', 'Hadoop, Cloudera', 'CDH, Hortonworks HDP, Google Cloud Platform, Amazon web service, Twitter streaming data', 'Senior Big Data Consultant', 'Positive Bioscience – Mumbai, India', 'to Dec-2013', 'Project Name: Next Generation DNA Sequencing Analysis Client: Positive', 'Bioscience Responsibilities:', 'Jan-2013', '•  Developed a Hadoop MapReduce program to perform sequence alignment on NGS data.', '•', 'The  MapReduce  program  implements  algorithms  such  as  Borrows-Wheeler  Transform  (BWT),', 'Ferragina-Manzini  Index  (FMI),  Smith-Waterman  dynamic  programming  algorithm  using  Hadoop', 'distributed cache.', '•  Design  and  development  of  software  for  Bioinformatics,  Next  Generation  Sequencing  (NGS)  in', 'Hadoop  MapReduce  framework,  Cassandra  using  Amazon  S3,  Amazon  EC2,  Amazon  Elastic', 'MapReduce(EMR).', '•  Developed Hadoop MapReduce program to perform custom Quality Check on genomic data.  Novel', 'features  of  the  program  included  capability  to  handle  fileformat/sequencing-machine  errors,', 'automatic  detection  of  base-line  PHRED  score  and  being  platform  agnostic  (Illumina,  454  Roche,', 'Complete Genomics, ABI Solid input format data).', '•  Developed a Hadoop MapReduce program to perform sequence alignment on sequencing data. The', 'MapReduce program implements algorithms such as Borrows-Wheeler Transform (BWT), Ferragina-', 'Manzini  Index  (FMI),  SmithWaterman  dynamic  programming  algorithm  using  Hadoop  distributed', 'cache.', '•  Configured and ran all MapReduce programs on 20-30 node cluster (Amazon EC2 spot instances) with', 'Apache Hadoop-1.4.0 to handle 600GB/sample of NGS genomics data.', '•  Configured  a  20-30  node  (Amazon  EC2  spot  Instance)  Hadoop  cluster  to  transfer  the  data  from', 'Amazon  S3  to  HDFS  and  HDFS  to  Amazon  S3  and  also  to  direct  input  and  output  to  the  Hadoop', 'MapReduce framework.', 'Successfully ran all Hadoop MapReduce programs on Amazon Elastic MapReduce framework by using', 'Amazon S3 for Input and Output.', '•', '•  Developed java Restful web services to upload data from local to Amazon S3, listing S3 objects and', 'file manipulation operations.', '•  Developed  MapReduce  programs  to  perform  Quality  Check,  Sequence  Alignment,  SNP  calling,', 'SV/CNV detection on single-end/paired-end NGS data.', '•  Designed and transmitted a RDBMS(SQL) Database to NOSQL Cassandra Database.', 'Hadoop Developer', 'PointCross.com - Bangalore, India', '2012', 'Nov-2011 to Jan-', 'Project Name: DDSR (Drilling Data Search and Repository)', 'This project aims to provide analytics for Oil and Gas exploration data. This DDSR repository build by using', 'HBase, Hadoop and its sub projects. We are collecting thousands of wells data from across the globe. This', 'data is stored in Hbase and Hive by using Hadoop MapReduce jobs. On top of this data we are building', 'analytics for search and advanced search.', 'Project Name: Seismic Data Server & Repository (SDSR™)', 'Our Seismic Data Server & Repository solves the problem of delivering, on demand, precisely cropped SEG-Y', 'files for instant loading at geophysical interpretation workstations anywhere in the network. Based on', 'Hadoop file storage, Hbase™ and MapReduce technology, the Seismic Data Server brings fault-tolerant', 'petabyte-scale store capability to the industry. Seismic Data Server supports post-stack traces now with pre-', 'stack support to be released shortly.', 'ADDITIONAL INFORMATION:', 'EDUCATION:', '•  Bachelor of Engineering in Computer Science and Engineering, University of VTU Bangalore,', 'Karnataka, India, 2011.', '•  Diploma in Computer Science and engineering University of KAE,', 'Bangalore, Karnataka, India, 2008', 'REFERENCE LINKS:', 'LinkedIn:  https://in.linkedin.com/in/sandishkumar', 'Twitter: https://twitter.com/sandishsany', '•', '•', '•  GitHub: https://github.com/SandishHadoop', '•', 'Skype: sandishhadoop']",5
23,//nb/corp/Users/NY/NY16/sbhardwa/@nbcfg/Desktop/Python codes/PDFextract/New folder/CV\Nick_S-HKARP.pdf,1.038416114,data busi analyt univers year pipelin servic degre demonstr histori summari ,"['aws{3}', 'docker{0},', 'sql{2}', 'hadoop{3}', 'hive{1}', 'teradata{0},', 'scala{0},', 'kubernetes{0},', 's3{1}', 'amazon redshift{0},', 'python{2}', 'matlab{0},', 'django{0},']",12,"['The University of Chicago Booth School of Business', ""Master's degree,\xa0Business Analytics,\xa02012\xa0-\xa02014"", 'Jawahar Lal Nehru University', 'Master of Computer Applications - MCA,\xa0Computer Applications,\xa02004\xa0-\xa02007', 'Savitribai Phule Pune University', ""Bachelor's degree,\xa0Computer Science ,\xa02001\xa0-\xa02004"", 'Nick S.', 'Norwalk, Connecticut', 'Big Data, IoT & ML - Kafka, Spark, Hadoop, EMR, Airflow, Redshift, Kinesis, Tensorflow,', 'AWS, R, Python, Power BI and SQL']","['Associate Vice President - BI & Analytics Solution at aPriori Business Intelligence, LLC', 'March 2015 \xa0-\xa0 Present\xa0 (4 years 7 months)', 'aPriori Business Intelligence is a consulting organization helping global organizations to transform', 'their businesses through data. We generate analytics from data stored in multiple silos.', 'Our services include - Big Data, Data Integration, Reporting & Visualization, ETL, Data Warehouse,', 'Advance Analytics', 'Data Engineering Services includes - Data Pipelines, Data Lakes and Data Analytics', 'Big Data Technologies - Spark, Kafka, Hadoop, HBase, Presto, Drill, mongoDB, Hive, MapReduce,', 'Cassandra', 'AWS Tech Stack - EMR, Kinesis, Data Pipeline, Athena, Redshift, DynamoDB, RDS, S3, Kafka', 'Services', 'Sr. Solutions Consultant - Data Analytics at EY', 'June 2010 \xa0-\xa0 May 2012\xa0 (2 years)', 'Project Lead at Accenture', 'June 2007 \xa0-\xa0 May 2010\xa0 (3 years)']",8
25,//nb/corp/Users/NY/NY16/sbhardwa/@nbcfg/Desktop/Python codes/PDFextract/New folder/CV\Pooja_Bhatia.pdf,1.037595771,month pooja year experi technolog mdm citiustech issu endeavor ,"['aws{0},', 'docker{0},', 'sql{1}', 'hadoop{0},', 'hive{0},', 'teradata{0},', 'scala{0},', 'kubernetes{0},', 's3{0},', 'amazon redshift{0},', 'python{0},', 'matlab{0},', 'django{0},']",1,"['Vivekananda Institute of Technology', 'Bachelor of Engineering (B.E.),\xa0Information Technology,\xa02007\xa0-\xa02011', 'Pooja Bhatia', 'Greater New York City Area', 'Data Engineer at Facebook', 'pooja.sidhani@gmail.com - 8572079470']","['Data Engineer at Facebook', 'December 2017 \xa0-\xa0 Present\xa0 (1 year 10 months)', 'Technical Lead - Informatica MDM at CitiusTech', 'October 2016 \xa0-\xa0 December 2017\xa0 (1 year 3 months)', 'Senior Software Engineer at CitiusTech', 'April 2016 \xa0-\xa0 September 2016\xa0 (6 months)', 'Senior Software Engineer at CitiusTech', 'October 2011 \xa0-\xa0 April 2016\xa0 (4 years 7 months)']",6
5,//nb/corp/Users/NY/NY16/sbhardwa/@nbcfg/Desktop/Python codes/PDFextract/New folder/CV\Buddhayan_Ray-HKARP.pdf,1.037063621,buddhayan work hadoop veri year experi big data level solut mapreduc great recommend analyst project job time manag use compon natur technic good asansol engin orient resourc team charm logist valuabl attitud ,"['aws{7}', 'docker{0},', 'sql{0},', 'hadoop{12}', 'hive{2}', 'teradata{0},', 'scala{0},', 'kubernetes{0},', 's3{1}', 'amazon redshift{0},', 'python{2}', 'matlab{0},', 'django{0},']",24,"['Asansol Engineering College', 'B.Tech,\xa0Computer Science & Engineering', 'Buddhayan Ray', 'Kolkata, West Bengal, India', 'AWS Certified Solution Architect | AWS Big Data & Cloudera Hadoop | Databricks | Spark |', 'Python | Java', '7 people have recommended Buddhayan', '""Buddhayan\'s thought process is very result oriented and he has got go getter attitude. He can', 'excel in any circumstances and environment. He is very technical person with good attitude.""', '—Anup Kumar Bhuiya,\xa0Technical Project Manager,\xa0 Tech Mahindra,\xa0 managed Buddhayan at', 'Cognizant Technology Solutions', '""Buddhayan is an excellent resource and a master at programming. His ability to listen and', ""understand his clients' needs allows him to consult effectively and get job done.He is positive and"", 'helpful. He has never hesitated to provide support when needed. I highly recommend him!.""', '—Biswanath Banerjee,\xa0Program Analyst,\xa0 Web Spiders,\xa0 managed Buddhayan at Indianelite.com']","['AWS Cloud & Big Data Consultant at Tata Consultancy Services', 'May 2016 \xa0-\xa0 Present\xa0 (3 years 5 months)', 'AWS Big Data Platform & Cloudera Hadoop Consultant', 'Senior Developer at Cognizant Technology Solutions', 'February 2010 \xa0-\xa0 May 2016\xa0 (6 years 4 months)', 'Java/J2ee & Hadoop Developer', 'Application Analyst at First Data Corporation', 'December 2013 \xa0-\xa0 September 2015\xa0 (1 year 10 months)', 'Big Data Hadoop Developer', 'Application Developer at Indianelite.com', 'October 2009 \xa0-\xa0 December 2009\xa0 (3 months)', 'Java/J2EE Developer', 'Application Developer at Time Vision Infotech', 'September 2008 \xa0-\xa0 October 2009\xa0 (1 year 2 months)', 'Java/J2EE Developer']",8
38,//nb/corp/Users/NY/NY16/sbhardwa/@nbcfg/Desktop/Python codes/PDFextract/New folder/CV\Will_Fitzgerald-Hadoop-DE.pdf,1.036136918,data engin team hardwar design technic year texa task hpe new subsystem idea python engag extern fair lifecycl process person analyz qualiti ,"['aws{0},', 'docker{0},', 'sql{0},', 'hadoop{0},', 'hive{0},', 'teradata{0},', 'scala{0},', 'kubernetes{0},', 's3{0},', 'amazon redshift{0},', 'python{2}', 'matlab{0},', 'django{0},']",2,"['The University of Texas at Austin', 'ECE', 'Activities and Societies:\xa0 University of Texas Cycling Team', 'Will Fitzgerald', 'New York, New York', 'Data Engineer', '1 person has recommended Will', '""I worked with Will for 4 years at HP/HPE. Will brings a lot of energy and new ideas to his work', 'and has a very engaging and positive personality. He is a team player and is highly regarded by', 'other members of the team. In all phases of the PCB product lifecycle Will approached his work', 'with rigorous engineering discipline. As the owner of the memory subsystem he delivered a design', 'that has been recognized by the quality group for meeting and exceeding quality goals. In addition', 'to hardware design, Will also participated in several cross-functional teams for RCA efforts and', ""process improvements. He always tackled tasks head on and showed respect for other people's"", 'ideas and concerns. In analyzing problems he always looked for a more efficient solution, including', 'taking the initiative to write scripts for test automation and data gathering. When time allowed he set', 'out to improve on or learn new technical topics. I enjoyed working with Will and would very much', 'look forward to working with him again if given the opportunity.""', '—Chris B.,\xa0Principal Lead Hardware Engineer,\xa0 L3 Technologies,\xa0 managed Will indirectly at', 'Hewlett Packard Enterprise']","['Data Engineer at Forcepoint', '2018 \xa0-\xa0 Present\xa0 (1 year)', '• Lead data engineer on multiple UEBA engagements', '• Leveraging python and our custom stack to enable client objectives', '•\xa0Currently focused on commercial & government insider threat detection', 'Technical Advisor at Insight Data Science', '2018 \xa0-\xa0 Present\xa0 (1 year)', '• Data engineering technical advisor, 19A + 19B', '•\xa0Data engineering fellow, 18B', 'Hardware Design Engineer V at Hewlett Packard Enterprise', '2012 \xa0-\xa0 2016\xa0 (4 years)', '•\xa0Hardware design lead on Superdome X supercomputing platform', '•\xa0Designed and implemented the memory subsystem and crossbar board', '•\xa0Developed python scripts for test automation and data analytics', '•\xa0Regularly contributed on internal and external root cause investigations', '•\xa0General point of contact for hardware support', ""• HPE Tech Con '16 poster fair presenter""]",6
3,//nb/corp/Users/NY/NY16/sbhardwa/@nbcfg/Desktop/Python codes/PDFextract/New folder/CV\Asher_Woodbury.pdf,1.030509133,data counselor client year month school scienc degre brown univers journal polit design york advisor lab seri number ,"['aws{0},', 'docker{0},', 'sql{0},', 'hadoop{0},', 'hive{0},', 'teradata{0},', 'scala{0},', 'kubernetes{0},', 's3{0},', 'amazon redshift{0},', 'python{0},', 'matlab{0},', 'django{0},']",0,"['Brown University', ""Bachelor's degree,\xa0Computer Science,\xa02013\xa0-\xa02017"", 'Activities and Societies:\xa0 Published author in the Brown Political Review, Meiklejohn Peer Advisor for', 'first year students, Captain of the Brown University Ultimate Frisbee Team', 'Bard High School Early College Queens', ""Associate's degree,\xa0Liberal Arts,\xa02009\xa0-\xa02013"", 'Asher Woodbury', 'New York, New York', 'Data Engineer at Simon Data']","['Data Engineer at Simon Data', 'September 2017 \xa0-\xa0 Present\xa0 (2 years 1 month)', ""Surface clear insights from raw data to drive more flexible targeting for our clients' messaging."", 'Develop and maintain multiple client data pipelines.', 'Technical advisor to ensure client success', 'Technology Associate at Bridgewater Associates', 'June 2016 \xa0-\xa0 August 2016\xa0 (3 months)', 'Worked on cost controls for Amazon Web Services, including system analysis, product', 'management and software design/development.', 'Teaching Assistant at Brown University Department of Computer Science', 'August 2015 \xa0-\xa0 December 2015\xa0 (5 months)', 'Held regular office hours to assist students with course concepts and projects, and led weekly lab', 'sessions on topics including Linux, Java and program design.', 'Head Counselor at Morningside Montessori School', 'June 2009 \xa0-\xa0 July 2015\xa0 (6 years 2 months)', 'Promoted quickly. Began as Counselor in Training in 2009, promoted to Junior Counselor in 2010,', 'promoted again to Assistant Counselor in 2013, and again to Head Counselor in 2014.']",8
6,//nb/corp/Users/NY/NY16/sbhardwa/@nbcfg/Desktop/Python codes/PDFextract/New folder/CV\Chengzhi_Zhao.pdf,1.029418729,engin use data process report server etl year month pipelin manag reduc internship univers wareh warehous revenu reconcili june model wireless gener activ autom scale core york salesperson product airflow feedback record records master ,"['aws{1}', 'docker{1}', 'sql{4}', 'hadoop{1}', 'hive{2}', 'teradata{2}', 'scala{3}', 'kubernetes{2}', 's3{1}', 'amazon redshift{0},', 'python{2}', 'matlab{0},', 'django{0},']",19,"['University of Florida - Warrington College Of Business', 'Master of Science,\xa0Information System & Operation Management,\xa02011\xa0-\xa02013', 'Activities and Societies:\xa0 Association of Information System', 'Wuhan University of Technology', 'Bachelor of Management,\xa0Marketing,\xa02007\xa0-\xa02011', 'Activities and Societies:\xa0 Student Union, Association of Marketing, Association of Future Management', 'Chengzhi Zhao', 'New York, New York', 'Sr. Data Platform Engineer']","['Sr. Data Platform Engineer at Meetup', 'February 2018 \xa0-\xa0 Present\xa0 (1 year 8 months)', '• Reduced data pipeline latency from 24 hours to minutes to improve the data analysis and machine', 'learning modeling quality with near real-time dataset using MySQL(binlog), Kinesis and Flink.', '• Designed and implemented ETL pipeline with up to 500 distributed concurrent tasks using Apache', 'Airflow.', '• Reduced ETL operation cost by 30% on ETL pipeline by processing delta dataset only in Spark', '(Scala).', '• Improve data pipeline stability and scalability by utilizing Kubernetes and auto scaling.', '• Built CI/CD pipeline for private python packages on Nexus 3 server.', 'Data Engineer at Meetup', 'April 2017 \xa0-\xa0 February 2018\xa0 (11 months)', 'Developer II at Walmart', 'December 2014 \xa0-\xa0 April 2017\xa0 (2 years 5 months)', '• Created revenue reconciliation matching rules engine to improve wireless payment to receivable', 'match rate to 98% and reduced unapplied cash by 5% monthly.', '• Developed pharmacy revenue reconciliation engine.', '• Built data warehouse in dimensional modeling with star/snowflake schema and built ETL process', 'using SSIS, Teradata, Hive.', '• Built near real-time ETL and dashboard to process sales metrics data.', '• Led agile team to develop monthly wireless revenue reconciliation and automate journal entry', 'process for accounting department.', 'Developer at Meridian Behavioral Healthcare, Inc.', 'June 2013 \xa0-\xa0 December 2014\xa0 (1 year 7 months)', '• Developed an incident management system for incident reports that track records.', '• Developed a data-driven Survey Scheduler to automate the process of generating and delivering', 'surveys for each client using Java, BIRD reporting engine and QUARTZ', '• Built an ETL process to extraction 5,000 records/day, validated and loaded data to data', 'warehouse using SSIS, SSAS', 'Software Engineer Internship at Infinite Energy Inc', 'January 2013 \xa0-\xa0 May 2013\xa0 (5 months)', 'Programmer at University of Florida', 'May 2012 \xa0-\xa0 May 2013\xa0 (1 year 1 month)', 'Software Engineer Internship at HARN Museum of Art', 'January 2012 \xa0-\xa0 April 2012\xa0 (4 months)', 'Marketing & Management Internship at PING AN INSURANCE (GROUP) COMPANY OF', 'CHINA ,LTD', 'June 2009 \xa0-\xa0 August 2009\xa0 (3 months)', '• Assisted in organizing products, customer, and salesperson conferences.', '• Arranged social activities and led group discussions, delivered core value to the customer and', 'gathered feedback.', '• Interviewed “Best Sales Person of the Week” and generated motivating reports that shared', 'experiences with the local company, with each report reviewed more than 300 times and received', 'good comments.']",9
35,//nb/corp/Users/NY/NY16/sbhardwa/@nbcfg/Desktop/Python codes/PDFextract/New folder/CV\Vijay_Kolla.pdf,1.026689421,year month architect jersey blue nation institut engin ,"['aws{0},', 'docker{0},', 'sql{0},', 'hadoop{0},', 'hive{0},', 'teradata{0},', 'scala{0},', 'kubernetes{0},', 's3{0},', 'amazon redshift{0},', 'python{0},', 'matlab{0},', 'django{0},']",0,"['Motilal Nehru National Institute Of Technology', 'ME,\xa0Control Systems & Engg,\xa02000\xa0-\xa02002', 'Kakatiya University', 'BTech,\xa0EEE,\xa01996\xa0-\xa02000', 'Vijay Kolla', 'Newark, New Jersey', 'Data Engineer at Compass']","['Data Engineer at Compass', 'December 2018 \xa0-\xa0 Present\xa0 (10 months)', 'Senior Manager EDW - ETL Architect at COTY Inc', 'September 2014 \xa0-\xa0 December 2018\xa0 (4 years 4 months)', 'ETL Architect at Horizon Blue Cross Blue Shield of New Jersey', 'October 2011 \xa0-\xa0 August 2014\xa0 (2 years 11 months)', 'Sr. ETL Designer at Bank of America', 'August 2009 \xa0-\xa0 October 2011\xa0 (2 years 3 months)', 'Senior Specialist at Hewlett Packard', 'March 2007 \xa0-\xa0 July 2009\xa0 (2 years 5 months)', 'Senior Specialist at HP/Knightsbridge Solutions LLC', 'February 2006 \xa0-\xa0 April 2009\xa0 (3 years 3 months)', 'Assistant Systems Engineer at Tata Consultancy Services', '2002 \xa0-\xa0 2006\xa0 (4 years)']",16
7,//nb/corp/Users/NY/NY16/sbhardwa/@nbcfg/Desktop/Python codes/PDFextract/New folder/CV\Christopher_Hansen.pdf,1.018039847,product production data engin spotifi year month pipelin servic drive variou new track research model school financi power artist price analyst music creat bank manag use compani present busi cloud market featur trade board metric oper fan analys perform growth pitch law improv ,"['aws{0},', 'docker{0},', 'sql{1}', 'hadoop{1}', 'hive{0},', 'teradata{0},', 'scala{3}', 'kubernetes{0},', 's3{0},', 'amazon redshift{0},', 'python{1}', 'matlab{0},', 'django{0},']",6,"['Massachusetts Institute of Technology', 'BS,\xa0Mathematics, Management Science,\xa02005\xa0-\xa02009', 'Taipei American School', 'Christopher Hansen', 'Greater New York City Area', 'Data Engineer at Spotify']","['Software Engineer at Spotify', 'September 2015 \xa0-\xa0 Present\xa0 (4 years 1 month)', 'Building pipelines and services to drive data products.', 'Tools: Scio (Google Cloud Dataflow), Scalding, Apache Crunch, Google BigQuery, Google', 'BigTable, Google Cloud SQL, GraphQL, Luigi', 'Languages: Scala, Java, Python', '- Developed Java backend micro-services and Scala pipelines to power artist and rightsholder', 'facing', 'playlist pitching platform', '- Rolled out the next iteration of Spotify’s engineering career development framework to empower', 'engineers to grow as either individual contributors or managers', '- Prototyped real-time stream count service and pipeline, which was sponsored and productionized', 'into the Spotify for Artists mobile app-• Devised and implemented attribution model and Scala', 'pipeline to track downstream streams of tracks stemming from on-platform and off-platform', 'campaigns', '- Built data pipelines to target drop-day new release notifications to fans and followers of artists with', 'new content', '- Developed data pipelines driving metrics in Spotify Fan Insights, the first iteration of Spotify for', 'Artists, using Apache Crunch framework', 'Product Development Analyst at Spotify', 'July 2014 \xa0-\xa0 September 2015\xa0 (1 year 3 months)', '- Support A/B testing of music recommendation features and evaluate test results', '- Conduct in-depth investigations into how users engage with programmed music features and', 'recommendations to drive product development', '- Define squad metrics and create pipelines and dashboards to track progress and growth', 'Analyst at Spotify', 'July 2012 \xa0-\xa0 June 2014\xa0 (2 years)', '- Analyzed feature effectiveness in surfacing new and relevant track and artist discoveries, and', 'created', 'a data pipeline to track music discovery', '- Created an email database and pipeline to drive marketing and trial retention email campaigns', '- Developed metadata pipeline to integrate ad server and sales data with Hadoop data to allow for', 'improved ad metrics reporting', '- Supported various departments (Ads, Marketing, Content, PR, Product, BD, Legal) with ongoing', 'analyses, data pipeline implementation, A/B test evaluations, and dashboard development', 'Associate at Novantas', 'June 2010 \xa0-\xa0 June 2012\xa0 (2 years 1 month)', '- Optimized term product renewal pricing to maximize spread revenue by creating elasticity models', 'in SAS', '- Created a dynamic small business checking lineup restructuring tool with an Excel front-end and', 'Access back-end for a leading Canadian bank', '- Installed and implemented a deposit pricing tool for a leading U.S. regional bank', 'Business Analyst at Gotham Consulting Partners', 'September 2009 \xa0-\xa0 May 2010\xa0 (9 months)', '- Developed a proactive investment strategy for a $1B private equity fund', '- Devised a growth strategy model for a $1.2B exterior building products manufacturer and supplier', '- Conducted an operations diagnostic assessment for a $45MM producer of personal care products', '- Performed customer and market due diligence research for a $200MM safety products', 'manufacturer', 'Investment Banking Summer Analyst at UBS', 'June 2008 \xa0-\xa0 August 2008\xa0 (3 months)', '- Conducted extensive research and performed analyses based on historical and projected financial', 'data to identify industry trends for use in company presentations', '- Created profiles of potentially acquirable utility assets and power plants for use in pitch materials', '- Generated acquisition and trading comparables from various financial and regulatory documents', 'for a board presentation', 'Research Assistant at MIT Sloan School of Management', 'October 2007 \xa0-\xa0 May 2008\xa0 (8 months)', 'Assisted Senior Lecturer John Akula in his research of carbon emissions trading, EU transportation', 'law, and anti-monopoly law.', 'Extern at yOOnew, Inc.', 'January 2008 \xa0-\xa0 February 2008\xa0 (2 months)', '- Researched and devised a search engine optimization plan to improve traffic to the startup', 'company’s website', '- Created a plan to improve community building among users of the company website', '- Researched sports stadium data to improve pricing models', '- Conducted online marketing through the use of blogs, message boards, and forums', 'Intern/Assistant at Watson Wyatt', 'June 2007 \xa0-\xa0 August 2007\xa0 (3 months)', '- Analyzed financial reports for trends in compensation changes resulting in changes in accounting', 'standards', '- Studied various proxy statements to determine general patterns in the compensation discussion', 'and analysis section', '- Used quantitative means to determine relationships between various performance indicators for', 'several large corporations']",8
4,//nb/corp/Users/NY/NY16/sbhardwa/@nbcfg/Desktop/Python codes/PDFextract/New folder/CV\Benjamin_Salah-HKARP.pdf,1.009462086,year ride music engin month book new york car taxi price data scientist base ,"['aws{0},', 'docker{0},', 'sql{0},', 'hadoop{0},', 'hive{0},', 'teradata{0},', 'scala{0},', 'kubernetes{0},', 's3{0},', 'amazon redshift{0},', 'python{0},', 'matlab{0},', 'django{0},']",0,"['Rutgers, The State University of New Jersey-New Brunswick', 'Bachelor’s Degree,\xa0Computer Science,\xa02015', 'Activities and Societies:\xa0 Undergraduate Student Alliance of Computer Scientists', 'Benjamin Salah', 'New York, New York', 'Software Engineer at Microsoft']","['Software Engineer at Microsoft', 'September 2019 \xa0-\xa0 Present\xa0 (1 month)', 'Software Engineer at PromoteIQ', 'March 2018 \xa0-\xa0 Present\xa0 (1 year 7 months)', 'Software Engineer at indify', 'January 2017 \xa0-\xa0 March 2018\xa0 (1 year 3 months)', 'indify is a data platform that uses a proprietary algorithm to predict future music stars. Using listener', 'data, social metrics and online trends, indify ranks and analyzes up-and-coming artists in order to', 'identify music icons far before they reach stardom.', 'Software Developer at Karhoo', 'December 2015 \xa0-\xa0 January 2017\xa0 (1 year 2 months)', 'Karhoo, the ride comparison app, gives you the flexibility to choose and book your ride based on', 'the features that matter most to you. Choose your ride based on price, pickup time, vehicle type, or', 'company. So whether you’re looking for a taxi, executive car or SUV, Karhoo has you covered.', 'Karhoo offers immediate pickup as well as pre-booking up to a year in advance. Transparent', 'pricing and no surge means you see your estimated fare before you book your ride.']",4
8,//nb/corp/Users/NY/NY16/sbhardwa/@nbcfg/Desktop/Python codes/PDFextract/New folder/CV\Daniel_Park.pdf,1.009349458,data month park bachelor seoul ,"['aws{0},', 'docker{0},', 'sql{0},', 'hadoop{0},', 'hive{0},', 'teradata{0},', 'scala{0},', 'kubernetes{0},', 's3{0},', 'amazon redshift{0},', 'python{0},', 'matlab{0},', 'django{0},']",0,"['Virginia Polytechnic Institute and State University', ""Bachelor's degree,\xa0Business Information Technology,\xa02010\xa0-\xa02014"", 'Seoul American High School', '2006\xa0-\xa02010', 'Daniel Park', 'Greater New York City Area', 'Data Engineer at 7Park Data']","['Data Engineer at 7Park Data', 'June 2015 \xa0-\xa0 Present\xa0 (4 years 4 months)', 'Solutions Analyst at Cognizant', 'August 2014 \xa0-\xa0 June 2015\xa0 (11 months)']",1
31,//nb/corp/Users/NY/NY16/sbhardwa/@nbcfg/Desktop/Python codes/PDFextract/New folder/CV\Siddharth_Kumar.pdf,1.005571601,siddharth team data engin facebook build servic hadoop passion product use technic busi solut month knowledg function technolog year support user environ analyt api friendli level deliv lab handl custom share divis softwar comput scienc process repositori lunexa segmint new sourc careerbuilder careerbuild airbnb societi indirectli symposium partner asset good ,"['aws{0},', 'docker{0},', 'sql{1}', 'hadoop{8}', 'hive{2}', 'teradata{1}', 'scala{2}', 'kubernetes{0},', 's3{0},', 'amazon redshift{0},', 'python{1}', 'matlab{0},', 'django{0},']",15,"['The University of Akron', 'Masters,\xa0Computer Science,\xa02008\xa0-\xa02010', 'Activities and Societies:\xa0 Sports Secretary of Indian Student Association', 'Jawaharlal Nehru Technological University', 'BTech,\xa0Information Technology,\xa02004\xa0-\xa02008', 'Activities and Societies:\xa0 Event coordinator for Ciencia 07 a National Level Technical Symposium', 'Presented technical papers and Participated at National level symposiums', 'Siddharth Kumar', 'New York, New York', 'Data Engineer at Facebook', '7 people have recommended Siddharth', '""Siddharth quickly became a reliable team player and leader. I look forward to working with him', 'again.""', '—David Hadley,\xa0Member, Client Success Team,\xa0 SearchBox, LLC,\xa0 managed Siddharth at Segmint', '""Sid has a passion for open source technologies (including Big Data). This passion is derived from', 'his joy of learning new technologies. When he came to Lunexa, Sid had very limited exposure to', 'the Hadoop ecosystem. But, by the end of his time with us he was one of our Hadoop experts. Self-', 'driven growth is a rarity and Sid has this in spades. Last, but not least, Sid is great to work with. He', 'has a fantastic work ethic and is a great team player. I hope our paths will cross again!""', '—David Cole,\xa0Chief Customer Officer,\xa0 Domino Data Lab,\xa0 managed Siddharth indirectly at', 'Claraview (formerly Lunexa, acquired in 2013)', '""I worked with Siddharth at CareerBuilder in Business Intelligence. Siddharth was always more than', 'willing to offer his assistance and expertise to help others learn quickly. He is always extremely', 'friendly, efficient and easy to do business with. He had a vast knowledge of the systems and as a', 'subject matter expert was able to clearly and effectively share knowledge between teams. It was an', 'extreme pleasure working with him while I had the chance.""', '—Mark LaCoursiere,\xa0Agile Delivery & Transformation Coach,\xa0 Elavon, Inc.,\xa0 worked directly with', 'Siddharth at CareerBuilder.com', '""I think the best thing I can say about Siddharth is that I would hire him back in less than one', 'second. I think that says it all.""', '—Rob Heiser,\xa0Founder,\xa0 Segmint,\xa0 managed Siddharth indirectly at Segmint', '""Siddharth is a passionate, talented and savvy person that I have had the pleasure of working with.', 'He works hard to make sure he delivers quality and has the ability to work in many different types', 'of environments and with different types of personalities. Siddharth utilizes his technical expertise', 'to build solutions and solve problems. He will be a valued asset to any organization and I hope our', 'paths cross again. All the best, Sid!""', '—David Choi,\xa0Client Partner,\xa0 Trianz,\xa0 managed Siddharth indirectly at Claraview (formerly Lunexa,', 'acquired in 2013)', '""Siddharth is not only passionate about his work but a quick learner. He has extensive knowledge', 'about all the available tools and technologies to develop rich, robust and scalable applications to', 'leverage the existing platform, which makes Siddharth a good technical resource to work with.""', '—Abdul Khader,\xa0Senior Software Engineer,\xa0 Career Builder,\xa0 worked with Siddharth at', 'CareerBuilder.com', '""Siddharth displayed a good level of passion and enthusiasm for implementing and bringing', 'Hadoop as a utility to our processes. During our shared goal, Siddharth, took many initiatives to', 'point us in the right direction for Hadoop implementation. I will definitely recommend him as an', 'excellent team player and a valuable asset for any organization, that he works for presently or in', 'the future.""', '—Kavita Ramachandran,\xa0Business Intelligence Manager,\xa0 CareerBuilder,\xa0 managed Siddharth', 'indirectly at CareerBuilder.com']","['Data Engineer at Facebook', 'August 2017 \xa0-\xa0 Present\xa0 (2 years 2 months)', 'Data Engineer at Airbnb', 'June 2014 \xa0-\xa0 August 2017\xa0 (3 years 3 months)', 'Founding member of the Data Engineering team at Airbnb responsible for building the core data', 'warehouse to track key business metrics for reporting and analytics', 'Work closely with Product Marketplace teams such as Search, Pricing and build real time data', 'pipelines for Machine Learning models.', 'Responsible for building powerful data sets that help understand user click stream behavior.', 'Onboard new engineers to the team and work with cross functional data teams.', 'Sr. Consultant at Claraview (formerly Lunexa, acquired in 2013)', 'February 2012 \xa0-\xa0 May 2014\xa0 (2 years 4 months)', 'Provide clients with business intelligence and data warehousing implementation and advisory', 'services', 'Recent Engagements:', 'Disney Interactive, Playdom division - Solutions Architect', '- Provide data integration and warehouse solutions for Disney mobile and social gaming division', '- Vertica, Hadoop, bash, python', 'Visa Inc. - Hadoop Developer', '- Map Reduce, Hive, HDFS, bash', 'Teradata Inc. - Aster Developer', '- Implement a Digital Marketing Solution using Aster analytic functions such as npath, attribution', 'and custom written functions using Aster Data Library implemented in Java.', 'Disney Interactive - ETL Developer', '- Provide data integration services for Disney Interactive across Salesforce and Google Doubleclick', 'systems.', '- Salesforce API, Google DFP, DSM API, Hadoop, Hive, Talend, Vertica', 'OSI Restaurant Partners -  SnapLogic Developer', '- Provide Integration services for HR data using SnapLogic to provide near real time updates', 'across heterogenous end points.', 'Data Warehouse Developer at CareerBuilder.com', 'April 2011 \xa0-\xa0 February 2012\xa0 (11 months)', 'Member of the Data Architecture team to design and develop work flows to support BI services by', 'consolidating data from heterogeneous data sources.', 'Provide services to handle big data using Hadoop/Hbase.', 'Service Owner for providing Predictive Analytics to the Sales team.', 'Service Owner for providing useful insight on customer purchase patterns and product performance', 'using Machine Learning and Statistical approaches.', 'Interact with internal and external users to develop technical designs.', 'Software Engineer at Segmint', 'May 2010 \xa0-\xa0 April 2011\xa0 (1 year)', 'Java developer to support Data Modeling and Information Retrieval.', 'Designing process flows for handling data transformations via Talend workflows and PL/PgSQL', 'scripts.', 'Identify solutions for handling big data.', 'Applying Machine Learning algorithms for pattern recognition and Knowledge Discovery.', 'Building reports on JasperSoft for business users and analysts.', 'Teaching Assistant at University of Akron, Ohio', 'December 2008 \xa0-\xa0 May 2009\xa0 (6 months)', 'Teaching Assistant to the Chair of Computer Science', 'Managing Lab Operations for:', '- Data Structures in JAVA.', '- Introduction to Computer Science (JAVA)', 'Manage Subversion repository for courses', 'Assisting Students with course work.', 'Application Developer (Intern) at Polaris Software Lab', 'August 2007 \xa0-\xa0 July 2008\xa0 (1 year)', 'Application Developer:', 'Daemon Job Scheduler to execute remote and local database jobs.', 'Comprehensive Database Support', 'Central Repository for storing and managing jobs.', 'User Friendly GUI / User roles authentication.', 'Crontab Functionality.', 'Environment: JAVA, J2EE, JDBC, JCrontab, Oracle 9i']",10
34,//nb/corp/Users/NY/NY16/sbhardwa/@nbcfg/Desktop/Python codes/PDFextract/New folder/CV\Taylor_Kolasinski.pdf,1.005183782,market state student associ societi year month revenu research paper technic trade strategi financ financi cost latenc member univers data peer account manag client econom natur organ analyst model analysi august septemb sector increas ,"['aws{0},', 'docker{0},', 'sql{1}', 'hadoop{0},', 'hive{0},', 'teradata{0},', 'scala{0},', 'kubernetes{0},', 's3{0},', 'amazon redshift{0},', 'python{0},', 'matlab{1}', 'django{0},']",2,"['University of North Carolina at Chapel Hill', 'Bachelor of Arts (BA),\xa0Mathematics and Economics,\xa02010\xa0-\xa02012', 'Activities and Societies:\xa0 Carolina Micro-finance Initiative, Carolina Investment Society, Carolina', 'Cross-Country and Track Club, Out of State Student Association', 'Georgetown University', 'Economics. Political Science.,\xa02010\xa0-\xa02010', 'Activities and Societies:\xa0 The Philodemic Society', 'Washington State University', 'Political Science.,\xa02008\xa0-\xa02009', 'Activities and Societies:\xa0 Opinion Columnist for the Daily Evergreen', 'Taylor Kolasinski', 'Brooklyn, New York', 'Data Engineer at WeWork']","['Data Engineer at WeWork', 'April 2016 \xa0-\xa0 Present\xa0 (3 years 6 months)', 'Software Engineer at WeWork', 'September 2014 \xa0-\xa0 April 2016\xa0 (1 year 8 months)', 'Software Engineer at Wizpert', 'August 2013 \xa0-\xa0 August 2014\xa0 (1 year 1 month)', 'Software Engineer at Spark451 Inc.', 'April 2013 \xa0-\xa0 August 2013\xa0 (5 months)', 'Founder at Oh Hey', 'August 2012 \xa0-\xa0 June 2013\xa0 (11 months)', '- Lone founder and developer of a social network that allows members of a university’s community', 'to anonymously connect with their peers based on their locations, creating a more natural and', 'organic way to connect with those near you online', '- Live at over a dozen universities', '- Programed application, both web and mobile, in HTML, PHP, CSS, Javascript, and MySQL', 'President at Out of State Student Association', 'August 2011 \xa0-\xa0 December 2012\xa0 (1 year 5 months)', '- Elected to represent the 2nd largest student organization consisting of nearly 3,000 out-of state', 'students', '- Served as the liaison to Student Government, University administrators and Board of Trustees', '- Oversaw management of $5,000 account and creation of yearly budget in conjunction with', 'Treasurer', '- Petitioned against proposed tuition increases to Board of Trustees and presented alternative plan', 'to increase tuition revenue', 'Research Paper Author at Academic Research in Applied Finance', 'August 2011 \xa0-\xa0 May 2012\xa0 (10 months)', '- Paper title: Don’t Be Late: The Cost of Latency', '- Analyzed cost of latency over time by developing a model-free empirical measure, work done in', 'collaboration with peer student and oversight by Professor Michael Aguilar (PhD, UNC)', '- Illustrated variability in cost of latency over a variety of technical trading strategies, asset classes', 'and market states of nature', '- Coded in Matlab and SAS for modeling optimal technical trading strategies, optimizing time', 'horizon used for analysis, computing cost of latency, and importing and augmenting second level', 'trade and quote data from WRDS server', 'Market Analyst at Carolina Investment Society', 'September 2010 \xa0-\xa0 May 2012\xa0 (1 year 9 months)', '- Recommended potential investments in energy and technology sectors for the $30,000 long-only', 'equity fund', '- Selected by the executive board to make final investment decisions and present those trade ideas', 'along with the corresponding fundamental analysis to the weekly assemblies of 75 members', '- Employed top-down approach evaluating global macroeconomic trends down to financial', 'performance of specific companies', '- Developed familiarity with functioning of markets, risk management by diversification and hedging,', 'shorting and valuation methodology', 'Research Analyst at FGI Research', 'September 2010 \xa0-\xa0 December 2010\xa0 (4 months)', '- Identified clients’ customer market research needs, created strategy for addressing those and', 'oversaw execution of strategy', '- Constructed statistical frameworks to meet scope and requirements of  clients’ research needs', 'and survey questionnaires', '- Developed comprehensive models outlining costs and incremental revenues associated with', 'different research strategies', '- Prepared financial statements and maintained general ledger with Head of Accounting', 'Congressional Intern at United States House of Representatives', 'January 2010 \xa0-\xa0 May 2010\xa0 (5 months)']",6
0,//nb/corp/Users/NY/NY16/sbhardwa/@nbcfg/Desktop/Python codes/PDFextract/New folder/CV\Aditya_Singh.pdf,1.004759211,data engin test use softwar month scienc report tutori etl client new york stack state languag legaci environ tableau ,"['aws{2}', 'docker{1}', 'sql{2}', 'hadoop{0},', 'hive{0},', 'teradata{0},', 'scala{0},', 'kubernetes{1}', 's3{1}', 'amazon redshift{0},', 'python{3}', 'matlab{0},', 'django{0},']",10,"['California State University-Sacramento', ""Master's degree,\xa0Computer Science,\xa02016\xa0-\xa02018"", 'Uttar Pradesh Technical University', 'Bachelor of Technology (B.Tech.),\xa0Computer Science,\xa02011\xa0-\xa02015', 'Aditya Singh', 'New York, New York', 'Data Engineer at Capgemini']","['Data Engineer at Capgemini', 'September 2019 \xa0-\xa0 Present\xa0 (1 month)', 'Working with New York based client to maintain their current ETL pipeline for customer tracking', 'data and integrate data feeds into the cluster.', 'Data Engineer at Cherre', 'July 2019 \xa0-\xa0 August 2019\xa0 (2 months)', 'Tech Stack: Python, Postgres, Google Cloud Platform, Airflow, Docker, Kubernetes, Hasura,', 'GraphQL, CircleCI.', '-> Maintaining and improving current data pipeline.', '-> Finding better solution to scale data pipeline.', '-> Ingest and integrate new datasets into Core schema.', 'Data Engineer at State Compensation Insurance Fund', 'April 2018 \xa0-\xa0 September 2018\xa0 (6 months)', 'Tech Stack: Python, AWS S3, AWS Redshift, Tableau, SAS', '• Creating and maintaining the ETL data pipeline', '• Improving the old legacy code having temp tables.', '• Use of SAS to generate the attribute mismatches report.', '• Using Tableau to do the ad-hoc reports.', 'Software Testing Engineer at QA InfoTech - Your Software Testing Partner', 'March 2015 \xa0-\xa0 August 2015\xa0 (6 months)', 'Tech Stack: Selenium, Bugzilla, Junit, Java', '->Evaluating and testing the Pearson publication online study tutorials.', '->Developed the test cases for each tutorial using Functional and System testing.', '->Validating the software working in different environment such as mac OS, Linux, windows.', '->Use of JUnit to build the Java test cases for running the software and perform unit testing.', '->Maintaining everyday bug reports for the clients using the Bugzilla software.']",4
28,//nb/corp/Users/NY/NY16/sbhardwa/@nbcfg/Desktop/Python codes/PDFextract/New folder/CV\Ronit_Gandhi.pdf,1.003702798,data engin project electron report compani guidelin maintain correct suppli univers new york address resolv ,"['aws{0},', 'docker{0},', 'sql{0},', 'hadoop{0},', 'hive{0},', 'teradata{0},', 'scala{0},', 'kubernetes{0},', 's3{1}', 'amazon redshift{0},', 'python{0},', 'matlab{0},', 'django{0},']",1,"['New York University', ""Master's degree,\xa0Computer Engineering,\xa02016\xa0-\xa02018"", 'University of Mumbai', 'Bachelor of Engineering (BE),\xa0Electronics and Telecommunications Engineering,\xa02012\xa0-\xa02016', 'Ronit Gandhi', 'Greater New York City Area', 'Data Engineer at Hudson Data']","['Data Engineer at Hudson Data', 'October 2018 \xa0-\xa0 Present\xa0 (1 year)', ""Software Engineer Internship at KAPSO - India's Leading Business Brokers"", 'December 2015 \xa0-\xa0 July 2016\xa0 (8 months)', '● Assisted in designing the website www.kapso.in for a start-up company and oversaw the', 'production of HTML5, CSS3 and JavaScript and maintained brand standards under company', 'guidelines.', '● Worked with developers to correct issues with current applications and collaborated with senior']",3
27,//nb/corp/Users/NY/NY16/sbhardwa/@nbcfg/Desktop/Python codes/PDFextract/New folder/CV\RAMESH_GANESAN-DE-HKARP.pdf,1.002364012,work use manag senior data engin ramesh program team hive spark project hadoop process experi sql strong python function busi intellig bank west databas script skill model technologies technolog autom creat expertis kimbal softwar stakehold provid particip open visual support knowledg initi cloud packag code payment liabil ,"['aws{2}', 'docker{0},', 'sql{8}', 'hadoop{5}', 'hive{8}', 'teradata{1}', 'scala{1}', 'kubernetes{0},', 's3{1}', 'amazon redshift{0},', 'python{7}', 'matlab{0},', 'django{0},']",33,"['Bharathiar University', 'Master’s Degree,\xa0Computer Programming,,\xa01998\xa0-\xa02001', 'RAMESH GANESAN', 'San Francisco Bay Area', 'Senior Data Engineer at GSN Games', '3 people have recommended RAMESH', '""It was great having Ramesh in the team. He always go above and beyond with the work assigned', 'to him. Always willing to take new challenges and learn new technologies. ""', '—Susil Panda,\xa0VP, Senior Technology Manager,\xa0 Wells Fargo,\xa0 managed RAMESH at Wells Fargo', '""Ramesh is an enthusiastic data engineer. I know him as an ETL development consultant at a client', 'that I worked for. He was working on an automation effort using Python, Unix and Informatica. He']","['• Worked in Oracle 10g, Oracle PL/SQL, Erwin, ETL DWH 4.4, UNIX, Sun Solaris, Shell Scripting', 'and Business objects XI.', '• Ability to Tune Queries to optimize performance using Explain Plans, Hints and Indexing', '• Excellent understanding of ER modeling for OLTP.', '• Expertise in dimension modeling (Star, Snowflake Schemas, Cube) for OLAP.', '• Proficient in data cleansing, ETL and denormalization.', '• Have clear understanding of Inmon and Kimball Methodologies.', '• Excellent understanding of Software Development Life-cycle and strong desire for quality.']",Not Found
32,"//nb/corp/Users/NY/NY16/sbhardwa/@nbcfg/Desktop/Python codes/PDFextract/New folder/CV\Sridip_Banerjee,_M.Sc-HKARP.pdf",1.002072866,data java softwar use api server framework applic month program design databas web servic algorithm languag process sridip shell script research gener manag cluster configur integr message messag tomcat spring engin blackberri year market comput scienc pattern spark bank perform performance load devic secur layer build stream busi high queri recognit valu network sdk highli orient kafka razor dataproc tool technolog paper sql reduct senior tracker huge societi excel compon analyt grail intellig assign focus protocol architectur idea googl ,"['aws{19}', 'docker{2}', 'sql{40}', 'hadoop{15}', 'hive{5}', 'teradata{0},', 'scala{11}', 'kubernetes{0},', 's3{2}', 'amazon redshift{0},', 'python{9}', 'matlab{4}', 'django{1}']",108,"['University of Windsor', 'M.Sc.(Thesis),\xa0Computer Science, Research: Machine Learning,\xa02009\xa0-\xa02010', 'Activities and Societies:\xa0 Graduate Student Society, Computer Science Student Society, ACM, V.I.S.A', 'Sridip Banerjee, M.Sc.', 'Oakville, Ontario, Canada', 'Senior Big Data/Cloud Developer(Java|Scala|Python|Spark|Kafka|AWS|GCP|Cloud DevOps|', 'Machine Learning)', 'sridip87@gmail.com - 6474585400', '4 people have recommended Sridip', '""Sridip has always been an absolute please to work with. He is a highly motivated and', 'knowledgeable software developer. His attention to detail is evident in the high quality of his work.', 'He provides great value to this team with his contributions.""', '—Brad Fach,\xa0Senior Principal Software Engineer,\xa0 NetSuite,\xa0 managed Sridip at BlackBerry', '""One of smartest developers I’ve ever met. Grand respect!""', '—Philip Posvaliuk,\xa0Senior Software Engineer (contract),\xa0 HSBC Global Banking and Markets,', 'worked directly with Sridip at Toronto Stock Exchange', '""In the world of Data Engineers focusing on software development and Data Scientist focusing', 'on analytics, Sridip stands-out as being able to play both roles. His ability to drive insights into', 'business value and then execute on it is what I would hire him for. ""', '—Jakub Kolakowski,\xa0Director, Engineering Transformation,\xa0 RBC,\xa0 managed Sridip at RBC', '""Sridip is a smart big data developer. He was the go to guru for any tough technical challenges we', 'faced in Spark, Scala, Hadoop...""', '—Brijesh Jaggi,\xa0Kafka Architect,\xa0 IBM,\xa0 worked directly with Sridip at RBC']","['Lead BigData Developer at TD Wealth', 'May 2018 \xa0-\xa0 Present\xa0 (1 year 5 months)', 'AWS SageMaker, AWS Lambda, S3, AWS RedShift, Route 53, AWS CLI, Amazon State Machine,', 'Amazon State Language(ASL), CloudFormation, AWS CloudTrail, AWS CloudWatch, AWS IAM,', 'AWS VPC, AWS SNS, AWS SQS, Terraform, Jenkins Pipeline, AppDynamics, FortifyScan,', 'DevOps, AWS RDS, AWS DynamoDB, AWS EC2, AWS KMS, AWS WorkSpace, AWS API', 'Gateway, AWS Cognito, Python, Boto3, Apache Spark 2.2, Scala 2.12, RDD, DataFrame API,', 'SparkSQL, Apache Kafka, Kafka cluster configuration Kerberos, Kafka Security SSL, Kafka broker,', 'KSQL, Cassandra, DSEFS, HDFS, YARN, Job Tracker, Task Tracker, Name Node configuration,', 'Data Node configuration, Spark Cluster, HA (High Availability), fault-tolerance, NoSQL, Autosys,', 'Functional Programming, Confluent Kafka, Apache Zookeeper, Apache Oozie, Spark Streaming,', 'Machine Learning algorithms, OLAP, OLTP, Big Data, Sqoop, Maven, SBT, Nexus, Git, Spark', 'Standalone, Cassandra cluster configuration, Cassandra performance optimization, Cassandra', 'Table Design, API Gateway Design, Spring Boot, Spring Batch, Java, OAuth, Stateless API', 'Design, Cucumber testing, Agile/Scrum, Google Cloud Platform(GCP), Google BigTable, Google', 'BigQuery, Google Cloud Storage, Google DataProc, Google CloudSQL, BigQuery ML, Google', 'Cloud Pub/Sub, Google Cloud Spanner, Google Cloud Functions, GCP StackDriver, ElasticSearch,', 'Avro, Parquet, ProtoBuf', 'Tech Lead, Machine Learning, Data Analytics I&TS at RBC', 'September 2016 \xa0-\xa0 May 2018\xa0 (1 year 9 months)', 'Apache Spark 2.0, Scala 2.11, Spark Streaming, Scala RDD, Distributed Systems, Hortonworks', 'Data Platform(HDP), Apache Ambari, Kerberos, KRB5 configuration, HBase, Hadoop, SparkSQL,', 'Real Time Streaming, Checkpointing, Name Node Configuration, Data Node Configuration, Edge', 'Node Configuration, NoSQL, Java, Functional Programming, Big data, Hadoop MapReduce, Spark', 'Cluster Configuration, BASH shell scripting, Kerberos configuration, Resource Manager(YARN),', 'Apache Kafka, Kotlin, SBT, JDBC, Oracle, Linux, Intellij Idea, ActiveMQ, GIT, Agile/Scrum,', 'Spark Dataframe API, Datameer, Hadoop, Hive on Tez, Tungsten, Hadoop Distributed File', 'System(HDFS),  Job Tracker, Task Tracker, HBase, Solr, ElasticSearch, Cassandra, Cassandra', 'Query Language(CQL), Python, PySpark, PySpark DataFrame API, Oozie, Big data, Hadoop', 'Multi Node Cluster Configuration, BASH shell scripting, Splunk, Splunk logging, Ansible, Dev-ops,', 'Docker Container, Maven, JDBC, Apache Nifi, Nifi Custom Processor, Sqoop, Linux, Machine', 'Learning Algorithms, Support Vector Machines, Supervised Learning, Clustering, Random Forest,', 'Spark Machine Learning Library(ML Lib), Data Science, Intellij Idea, Akka, scalamock, GIT, Agile/', 'Scrum, Seasonal Trend Decomposition, Linear Regression, Principal Component Analysis, Linear', 'Dimensionality Reduction, Linear Discriminant Analysis, Feature Reduction, Feature Selection,', 'Neural Networks, Deep Learning', 'Senior Big Data Architect at Scotiabank - Global Banking and Markets(Scotia Capital)', 'October 2015 \xa0-\xa0 September 2016\xa0 (1 year)', 'Apache Spark 1.6, Scala 2.11, Scala RDD, Spark Dataframe API, Distributed Systems, Jupyter', 'Big Data, Hortonworks Data Platform(HDP), Apache Ambari, Hadoop, Hive on Tez, SparkSQL,', 'Tungsten, Hadoop Distributed File System(HDFS),  Job Tracker, Task Tracker,  Name Node', 'Configuration, Data Node Configuration, Edge Node Configuration, NoSQL, HBase, Solr,', 'ElasticSearch, Cassandra, Cassandra Query Language(CQL), Java, Python, PySpark, PySpark', 'DataFrame API, Airflow scheduler, Oozie, Apache Flume, Functional Programming, Big data,', 'Hadoop MapReduce, Hadoop Multi Node Cluster Configuration, Spark Cluster Configuration,', 'Django, BASH shell scripting, Kerberos, Resource Manager(Yarn, Apache Mesos), Docker', 'Container, Apache Kafka, Maven, JDBC, PostgreSQL, Sqoop, Linux, Machine Learning', 'Algorithms, Support Vector Machines, Supervised Learning, Clustering, Apache Mahout, Spark', 'Machine Learning Library(ML Lib), Data Science, Intellij Idea, Akka, Spark Streaming, GIT, Capital', 'Markets, Agile/Scrum, Social Network Analysis(SNA), GraphDB, Neo4j', 'Senior Software Developer at Toronto Stock Exchange', 'January 2015 \xa0-\xa0 October 2015\xa0 (10 months)', 'Building a high performance trading and risk management engine that trades over the counter', '(OTC) derivatives using core Java and JBoss CDI framework. Developed messaging middleware', '(EIP, ActiveMQ, JBOSS EAP) to integrate with external systems (UnaVista-SOAP over JMS,', 'EuroClear-FTP-based SWIFT and Razor-proprietary JAXB over custom HTTPS). Built a distributed', 'cache framework using Hibernate second level cache and Jboss. Designed and developed', 'the business logic and DAO layer of performance-intensive system in core Java. Developed a', 'generic framework to support pagination based on Criteria Query API of Java Persistence API.', 'Implemented JSON server side portal endpoints.', 'Senior Software Developer at Quickplay', 'June 2014 \xa0-\xa0 January 2015\xa0 (8 months)', 'Java, J2EE, Hadoop, Hive, Hue, Hortonworks Data Platform, XML, XSLT, Spring, Android, Oracle', 'Weblogic, JavaScript, Spring Framework, JSON, Jackson', 'Senior Software Developer, Software Loading and Device Management, R&D at BlackBerry', 'June 2013 \xa0-\xa0 June 2014\xa0 (1 year 1 month)', 'Blackberry Handheld Applications: Software Loading Replication & Protocols R&D:', 'Developing handheld software loading and update infrastructure applications for Blackberry 10', 'smartphones.', 'Developing server side applications responsible for secure software updates for all active', 'Blackberry devices.', 'Developing high throughput RESTful java web services to be accessed by all active Blackberry', 'smartphones.', '+ some secret stuff', 'Technologies used:', 'Java 7, J2EE, High Scalability, Low latency, High throughput, Spring, Spring Annotations, Oracle', 'Stored Procedure, PL/SQL, Java Message Service(JMS), Multi-threaded Java, Java Concurrency,', 'High performance computing, Parallel programming, Object Relational Mapping(ORM), Hibernate,', 'Mobile Device Communication Protocols, Blackberry SDK, RESTful web services, Linux, Cygwin,', 'Distributed Systems, QNX, Spring transaction, XML, XSLT, XPATH, JAXB, JIBX, Maven, Jenkins,', 'Spring tool suite, Shell scripting, Blackberry 10 applications, Elastic search, NoSQL, MySQL', 'Galera Cluster, Jersey, Jackson, JSON, Postman, HTTP, GIT, Gerrit, Perforce, Apache Tomcat 7,', 'Distributed Java Virtual Machines(JVM), JAXP, SAX Parsing, Junit, XSD, XML schema, ActiveMQ,', 'Spring security, Spring annotations, sl4j, Mockito, memcached, Ehcache, MariaDB, JAX-RS,', 'Spring Aspect Oriented Programming(AOP), Log4j, Apache Lucene, Solr, EJB, Java NIO, Oracle', 'WebLogic, Android DoubleClick ad API, Android 4.4, JavaScript, MongoDB, Hadoop, Apache Hive,', 'Hue, Talend Enterprise Big Data, Pig, Mahout.', 'Tech Lead, Market Risk Analytics at RBC Capital Markets', 'May 2012 \xa0-\xa0 June 2013\xa0 (1 year 2 months)', 'Royal Bank of Canada Capital Markets : Trading and Market Risk', 'Wrote a web application in Groovy on Grails and Java using Hibernate as the ORM. Configured', 'the application in using Spring. Designed and developed the SQL server database. Deployed in', 'Tomcat in Linux.', 'Wrote stored procedures and triggers in SQL. Designed and developed an ETL (Extract-Transform-', 'Load) tool in Java to get data from several databases and run Pattern Recognition algorithm on it.', 'Designed and developed several Pattern Recognition, Machine Learning and Business Intelligence', 'algorithms in Java. Wrote korn shell scripts for the deployment and run time configuration of the', 'application. Deployed and wrote scripts in Tomcat and WebSphere.', 'Wrote scripts in unix and in Tidal Enterprise Scheduler for run time configuration. Used Apache poi', 'Java API to generate Microsoft Excel reports from the transformation phase.', 'Technologies used:', 'Java, Java Enterprise Edition(J2EE), JAXB, JMS, ActiveMQ, JPA, Hibernate, Hibernate Query', 'Language, JAXP, Spring, Spring Annotation, JSP, Servlet, Groovy, Groovy on Grails, Javascript,', 'CSS, jQuery, JDBC, Microsoft SQL Server, SQL, T-SQL, Linux, Shell Scripting, BASH, KSH, Perl', 'scripting, Solace Java Message-Oriented Middleware, Tidal Enterprise Scheduler, Autosys(JIL),', 'Maven, Apache Ivy, Apache ANT, Apache Tomcat, WebSphere application server, Machine', 'Learning Algorithms, Spring Tool Suite, XML Schema, XSD, DTD, XPath, SOAP, RESTful Web', 'Services, Design Pattern, Hadoop, NoSQL, MongoDB, Apache Mahout, Spring Transaction.', 'Software Engineer at Sandvine', 'September 2011 \xa0-\xa0 May 2012\xa0 (9 months)', 'Extracted huge unstructured data from a Policy Traffic Switch which does deep packet inspection', 'of huge network systems and developed different machine learning and statistical models to make', 'sense of that huge unstructured data pool.', 'Wrote the transformation phase of an Extract Transform Load application to extract data from', 'PostgreSQL database and developed different MicroStrategy data model to load data in the', 'Business Intelligence Server. Designed and developed databases and wrote stored procedures', 'and database triggers.', 'Deployed application in WebSphere and configured and performance tuned using IBM WebSphere', 'Admin tool. Used Service Oriented architecture to develop SOAP and RESTful web services using', 'J2EE web services components(like JAXB, JIBX).', 'Implemented database layer functionality with Object Relational Mapping tools like Hibernate', 'with JPA specifications. Developed the whole application in Spring framework and used different', 'modules of Spring including Spring security, Spring annotations, Spring IOC, Spring MVC and', 'Spring AOP, Spring DAO.', 'Extracted and transformed huge amount of network protocol level unstructured data and developed', 'Machine Learning algorithms to run on them.', 'Technologies used:', 'Java, J2EE, Spring MVC, Spring IOC, Spring Annotations, Multithreaded Java, MicroStrategy, Flex,', 'CSS, JavaScript, Struts, JSP, Unix, FreeBSD, Shell Scripting, Perl Scripting, Big Data Analytics,', 'Linear Regression, Clustering, Unsupervised Learning,  Data Mining, Data Warehousing, Object', 'Oriented Perl, Computer Networking, Network Policy Control Language, Policy Traffic Switch, C,', 'Deep Packet Inspection, PostgreSQL, Microsoft SQL Server, T-SQL, Stored Procedure, Database', 'Trigger, Object Relational Mapping, Hibernate, SOAP web services, RESTful Web Services, JMS.', 'Software Developer, Blackberry Enterprise Server R&D at Blackberry', 'September 2010 \xa0-\xa0 September 2011\xa0 (1 year 1 month)', '\uf0d8Implemented different web services and integration layer functionality of BES in Java Enterprise', 'Edition (J2EE). Designed and developed MS SQL Server 2008 databases', '\uf0d8Wrote stored procedures and triggers in SQL. Designed and developed an ETL (Extract-', 'Transform-Load) tool in Java to get data from several databases and run Pattern Recognition', 'algorithms on it and then process the data with Business Intelligence server(MicroStrategy).', '\uf0d8 Designed and developed several Pattern Recognition, Machine Learning and Business', 'Intelligence algorithms in Java', '\uf0d8 Developed an Automated Component Test Framework for components of BES in Java & Groovy', '\uf0d8 Implemented a XML Data Generator in Java and then fill XML templates with those generated', 'data', '\uf0d8 Implemented Java Web Services to send SOAP messages to different components of BES', '\uf0d8 Designed and developed a database in SQL server 2008 for our framework', '\uf0d8 Written XSLT to transform XMLs to Google’s Robot framework’s consumable format', '\uf0d8 Implemented a Tomcat web service in Groovy using Groovlets to query data from Rally(Agile', 'development website)web service and then publish our own web service', '\uf0d8 Implemented an Apache Tomcat 5.1 web service in J2EE using Java Servlets', '\uf0d8 Written a Domain Specific Language in C++ to manage Branch Integration in Perforce', '\uf0d8 Replaced ANT with a new generation Automated Software Build Process System called Gradle', 'for highly critical BlackBerry Enterprise Server Continuous Integration Build System', '\uf0d8 Implemented a “Pre-Flight” Build System for BlackBerry Enterprise Server CI Build, resulting 65%', 'less build failure affecting almost 80 developers', 'Technologies used:', 'Java, Perl, Python, Jython, Java Enterprise Edition(J2EE), JAXB, JMS, JPA, Hibernate, JAXP,', 'Spring, JSP, Servlet, Gradle, Groovy on Grails, Javascript, CSS, jQuery, Selenium, JDBC, SQL', 'Server, SQL, T-SQL, Linux, Shell Scripting, BASH, KSH, Maven, Ivy, ANT, Apache Tomcat, XML,', 'XSD, XPath, SOAP, RESTful Web Services, Design Pattern, XSLT, Cruise Control', 'Research Associate, Machine Learning Lab at University of Windsor', 'September 2009 \xa0-\xa0 September 2010\xa0 (1 year 1 month)', 'Pattern Recognition and Machine Learning Group, Department of Computer Science:', 'Implemented various Data Mining & Pattern Recognition algorithms in Java and C++', '\uf0d8 Implemented various Machine Learning classifiers in Java and MATLAB', '\uf0d8 Wrote scripts in Python,Perl,C Shell for feature generation for classification', '\uf0d8 Proposed an algorithm to increase Multiclass Classifier classification accuracy & wrote research', 'papers', 'Graduate Teaching Assistant, Department of Computer Science in', '1)Object Oriented Programming in Java(Fall 2009)', '2)Data Structure and Algorithm using Java(Winter 2010)', '3)Computer Architecture:Digital design(Summer 2010)', '\uf0d8Taught programming concepts in lab sessions and during tutoring hours.', '\uf0d8Prepared assignments and quiz questions.', '\uf0d8Evaluated assignments,quizzes,midterms and final exam papers.', '\uf0d8Helped professors to prepare course material and final exam questions.', 'Technologies used: Java, Python, Perl, C++, Machine Learning, Statistical Pattern Recognition,', 'Weka, Matlab, Natural Language Processing, Shell Scripting (C Shell, Korn Shell, BASH)', 'Machine Learning Researcher, Microelectronics Division, R&D at Saha Institute of Nuclear Physics', 'February 2009 \xa0-\xa0 September 2009\xa0 (8 months)', '\uf0d8 Developed Machine Learning algorithms for automated detection of cancerous liver from', 'Ultrasound images', '\uf0d8 Implemented the algorithms in Java and user interfaces with Java Swing and AWT package', '\uf0d8 Implemented various Image processing(Pattern Recognition and Machine learning) and Data', 'Mining algorithms in Java and C++', 'Technologies used: Java, J2EE(Java Enterprise Edition), JAXB, JAXP, JMS, Java Swing, JSP,', 'JDBC, JavaScript, Microsoft SQL Server, C++, Matlab, Statistical Pattern Recognition, Machine', 'Learning, Natural Language Processing, Image Processing, Korn Shell, Digital Signal Processing', 'Software Developer, Co-op at Computer Society of India', 'May 2008 \xa0-\xa0 August 2008\xa0 (4 months)', '\uf0d8 Developed a Secure Web Based Bus Reservation System with integrated fare management', 'system as well as e-ticketing while also including modules like Internet booking system, frequent', 'traveler database in Java Enterprise Edition architecture.', '\uf0d8 Coded in JSP and every logical layer in Java Enterprise Edition(J2EE) architecture', '\uf0d8 Designed and developed a database in Oracle 8i', 'Technologies used: Java, Java Enterprise Edition(J2EE), JAXB, JMS, JPA, JSP, Servlet,', 'Javascript, CSS, JDBC, Oracle 8i, SQL, PL-SQL, Linux, Shell Scripting, BASH, KSH, Perl', 'scripting, Java Message-Oriented Middleware, Maven, ANT, JBOSS, XML Schema, XSD, DTD,', 'XPath, SOAP, RESTful Web Services, Design Pattern', 'Programmer Analyst, Co-op at Globsyn Infotech', 'May 2007 \xa0-\xa0 August 2007\xa0 (4 months)', '\uf0d8 Developed a Car Dealership Automation System with Inventory Management System, Invoicing', 'System and Parts Inventory System and Customer Tracking Database', '\uf0d8 Coded in C\uf0d8 and developed in ASP.NET architecture, that interacted through ADO.NET with our', 'backend database SQL Server 2005', '\uf0d8 Designed and developed a database in SQL Server 2005', '\uf0d8 Designed user interface with Windows Forms Designer and Toolbox.']",13
10,//nb/corp/Users/NY/NY16/sbhardwa/@nbcfg/Desktop/Python codes/PDFextract/New folder/CV\Doug_Stone.pdf,0.989989705,data manag analyt price build power strategi year client month scalabl custom hopstop liquid algorithm ,"['aws{0},', 'docker{0},', 'sql{0},', 'hadoop{0},', 'hive{0},', 'teradata{0},', 'scala{3}', 'kubernetes{0},', 's3{0},', 'amazon redshift{0},', 'python{0},', 'matlab{0},', 'django{0},']",3,"['Cornell University', 'BA,\xa0Economics,\xa02001\xa0-\xa02005', 'Doug Stone', 'New York, New York', 'Data Engineer at Better.com', 'dougastone@gmail.com - +1 646-678-1507']","['Data Engineer at Better.com', 'March 2019 \xa0-\xa0 Present\xa0 (7 months)', 'Head of Data at ExecThread', 'May 2018 \xa0-\xa0 March 2019\xa0 (11 months)', 'Manager (Data Analysis) at Apple', 'July 2013 \xa0-\xa0 May 2018\xa0 (4 years 11 months)', 'Designed and implemented algorithms to support data management for the public transit feature,', 'focusing on scalable and high velocity data integration, internal tools and anomaly detection.', 'Director of Data Management and Analytics at HopStop.com', 'June 2012 \xa0-\xa0 July 2013\xa0 (1 year 2 months)', 'Focused on optimizing the sourcing, QA, processing, and organization of the vast streams of data', 'powering HopStop, while improving the mobile and web applications through analysis of user data.', 'Efforts included building processes and automation around the updating and validation of data', 'inputs, optimizing database design, and designing scalable algorithms to process the information.', 'Strove to make sense of a large variety of information types and to build algorithms on top of these', 'sources that learned from the rapid influx of data. Overall goal was to cultivate a data strategy that', 'allowed the business to grow in an agile, scalable, data-driven fashion.', 'Manager at Novantas', 'July 2009 \xa0-\xa0 June 2012\xa0 (3 years)', 'Management consultant with expertise in pricing and risk management strategy for financial']",10
37,//nb/corp/Users/NY/NY16/sbhardwa/@nbcfg/Desktop/Python codes/PDFextract/New folder/CV\Walter_Han.pdf,0.989516128,data databas year month code team applic tool sql python june intern deliv york provid ,"['aws{1}', 'docker{0},', 'sql{5}', 'hadoop{0},', 'hive{0},', 'teradata{0},', 'scala{0},', 'kubernetes{0},', 's3{0},', 'amazon redshift{0},', 'python{3}', 'matlab{0},', 'django{0},']",9,"['Northwestern University', 'BSEE,\xa0Electrical Engineering,\xa02007\xa0-\xa02011', 'Walter Han', 'New York, New York', 'Data Engineer at Facebook']","['Data Engineer at Facebook', 'January 2017 \xa0-\xa0 Present\xa0 (2 years 9 months)', 'Senior Data Engineer at Outcome Health (formerly ContextMedia, Inc.)', 'January 2015 \xa0-\xa0 January 2017\xa0 (2 years 1 month)', 'First data engineer hire at Contextmedia - architected and built data backend (AWS Redshift) using', 'Luigi to facilitate data movement.', 'Perform data wrangling and analysis using SQL and Python, using Tableau and Python to visualize', 'concepts.', 'Senior Database Developer at Enova Financial', 'July 2011 \xa0-\xa0 January 2015\xa0 (3 years 7 months)', '• Coordinate with business teams and application developers to model database structures, design', 'Rails application models, and deploy database code in a no downtime environment', '• Optimize code on both application (Rails) and database (PostgreSQL) side, addressing object-', 'relational impedance mismatch and poor/legacy data structures', '• Query writing and optimization in PostgreSQL database', '• Code stored procedures and triggers in PL/pgSQL', '• Implement internal database tools, jobs, and scripts using the best tool available (Perl, Python,', 'Ruby, or Bash)', '• Mentor and provide guidance to junior developers on best data practice as a member of internal', 'data architecture committee', 'Web Developer at Northwestern Univeristy', 'June 2010 \xa0-\xa0 May 2011\xa0 (1 year)', 'Develop and deliver content management systems for various departments at Northwestern', 'University using PHP and SQL.', 'Embedded Software Developer Intern at Synaccess Networks', 'June 2009 \xa0-\xa0 September 2009\xa0 (4 months)', 'Worked on a team at Synaccess Networks to develop and deliver a Linux operating system for an', 'ARM7TDMI CPU. Developed and ported this platform to application engineers.']",8
19,//nb/corp/Users/NY/NY16/sbhardwa/@nbcfg/Desktop/Python codes/PDFextract/New folder/CV\Maneesh_Menon.pdf,0.988668734,team use manag work data engin grubhub maneesh month projects process handl job busi intellig project veri analysi technolog time year experi client level end perform deliveri ensur complet solut script help skill execut scienc expertis tune warehous wareh insight report model variou stage effect ani knowledg hive design ,"['aws{0},', 'docker{0},', 'sql{3}', 'hadoop{1}', 'hive{2}', 'teradata{0},', 'scala{1}', 'kubernetes{0},', 's3{0},', 'amazon redshift{0},', 'python{1}', 'matlab{0},', 'django{0},']",8,"['University of Connecticut', ""Master's Degree,\xa0Master of Science in Business Analytics and Project Management,\xa02014\xa0-\xa02015"", 'Cochin University of Science and Technology', 'Bachelor of Technology (B.Tech.),\xa0Computer Science,\xa02005\xa0-\xa02009', 'Maneesh Menon', 'New York, New York', 'Lead Data Engineer at Grubhub', '4 people have recommended Maneesh', '""Maneesh is very committed, responsive and trustworthy. Maneesh in short span of time has won', 'various accolades in his engagements with clients and has the ability to independently manage', 'work and communicate effectively. He is very good team player and effective mentor. i wish him all', 'the very best in future endeavours. ""', '—Sathish Peethambaran,\xa0Director - Information Management & Analytics,\xa0 Barclays,\xa0 managed', 'Maneesh at Cognizant Technology Solutions', '""Maneesh worked with me on the data warehouse team. He was very knowledgeable on DataStage', 'ETL. He was very conscientious and hard working. He was given an assignment of researching', 'some issues on one of our more complex processes. He quickly became the expert and go-to', 'person for that process. Maneesh is a quick learner and would be an asset to any team.""', ""—Jamie Soule, PMP, CSM,\xa0Project Manager,\xa0 Lincoln Financial Group,\xa0 was Maneesh's client"", '""Maneesh was my lead in a Development & Production Support project for almost 2 years where he', 'guided me in various aspects from technical to behavioral. He is a very good friend & a person who', 'can always be looked up to for any problems/suggestions professionally & personally. His technical', 'expertise in Datastage ETL development, Unix Shell scripting & SQL is highly commendable.""', '—K V S Dheeraj Murthy,\xa0Senior Consultant - Technology,\xa0 Deloitte India (Offices of the US),', 'worked indirectly for Maneesh at Cognizant Technology Solutions', '""Manish was one of our star performers and did a fantastic job in enhancing and supporting a', 'Datawarehouse for an insurance client. Has excellent knowledge of IBM Infosphere Datastage and', 'DB2 and was one of the go to persons in the team for solving complex issues. I looked forward to', 'working with Manish again.""', '—Bijoy Abraham,\xa0Delivery Manager - Business Analytics,\xa0 DXC Technology,\xa0 managed Maneesh at', 'CSC']","['exposure to Hive, Pig and Sqoop.', '• Played a vital role in increasing offshore team size by five.', '• Lead the team from offshore in successfully delivering a data warehouse project and also', 'managed the project plans for a team of five.', '• Handled huge data-sets using big data and analytical tools.', '• Performed pre-processing and transformation with huge data-sets using Hive, Pig.']",Not Found
33,//nb/corp/Users/NY/NY16/sbhardwa/@nbcfg/Desktop/Python codes/PDFextract/New folder/CV\Suhita_Goswami.pdf,0.979333511,work york data engin month insight use suhita project technolog busi nation tableau design model carri report qualiti client societi movi intern market asset oper perform analyt skill social media compani build trend level team intellig variou june ,"['aws{0},', 'docker{0},', 'sql{0},', 'hadoop{1}', 'hive{0},', 'teradata{0},', 'scala{2}', 'kubernetes{0},', 's3{0},', 'amazon redshift{1}', 'python{0},', 'matlab{0},', 'django{0},']",4,"['New York University', 'Master’s Degree,\xa0Computer Science,\xa02015\xa0-\xa02017', 'Activities and Societies:\xa0 Member of Society of Women Engineers', ""SVKM's NMIMS Mukesh Patel School of Technology Management"", 'Bachelor of Technology (B.Tech.),\xa0Information Technology,\xa02010\xa0-\xa02014', 'Activities and Societies:\xa0 Member of Model United Nations Society. Participated and won awards at', 'national level Model United Nations Conferences', 'Suhita Goswami', 'Brooklyn, New York', 'Data Engineer at Google Cloud', '2 people have recommended Suhita']","['Data Engineer at Google', 'March 2019 \xa0-\xa0 Present\xa0 (7 months)', 'Solutions Consultant at Cloudera', 'October 2018 \xa0-\xa0 February 2019\xa0 (5 months)', 'Supported clients in building scalable solutions on the Hadoop ecosystem for diverse use cases.', 'Designed secure data pipelines, resolved cluster scalability, data distribution and processing', 'concerns.', 'Published technical assets in the form of engineering blogs around Apache Kafka and Apache', 'Impala.', 'Associate Consultant at Cloudera', 'June 2017 \xa0-\xa0 September 2018\xa0 (1 year 4 months)', 'Graduate Teaching Assistant at New York University', 'September 2016 \xa0-\xa0 May 2017\xa0 (9 months)', '- Implement learning plans designed by the professor for graduate level course of Computer', 'Networks', '- Handled queries and grade homework and exams', 'Business Analyst Intern at Altice USA', 'June 2016 \xa0-\xa0 August 2016\xa0 (3 months)', '• Worked with the Business Intelligence and Strategy Group in Data Profiling, Data Quality and BI', 'Development.', '• Developed data models and workflows on Alteryx to draw insights on customer demographics and', 'activity on different payment channels.', '• Performed data profiling and data quality testing of customer and product usage data on Netezza,', 'Oracle 10g and Amazon Redshift.', '• Carried out UAT and QA testing of Data cubes and reports on Microstrategy and Tableau for', 'Cable Operations division.', ""• Conceptualized, strategized and pitched the 'Business for your Business' product prototype for the"", 'Altice USA Intern Shark Tank.', '• Worked under the supervision of Director of Data Quality and the Director of Data Visualization for', 'the progress of the projects.', 'Summer Intern at Hansa Cequity', 'June 2015 \xa0-\xa0 July 2015\xa0 (2 months)', 'Performed data modeling and statistical analysis to analyze impact of social media on revenue of', 'movies.', '• Collated and cleaned data for different India movies and their social media footprints from', '2011-2015.', '• Designed various use\xa0cases and functions to extract useful parameters from raw data.', '• Established the validity of\xa0relationships between social media platforms and movie revenues using', 'regression models.', '• Documented and presented various phases and resulting insights of the project to the company', 'supervisors.', 'Business Technology Analyst at ZS Associates', 'September 2014 \xa0-\xa0 May 2015\xa0 (9 months)', '• Engaged with clients’ teams to understand and gather requirements and translate them to', 'effective use cases for data models and calculations.', '• Built assets for tracking sales and marketing campaign performance using data visualization', 'and reporting tools such as Tableau and Qlikview to gain insights in the marketing trends in the', 'Pharmaceuticals market in the USA.', '• Developed reporting assets in Tableau for clients to leverage from insights on performance trends', ""and major stakeholders in a leading transport company's  national presence."", '• Wrote technical manuals to work with the designed reports and tools efficiently.', '• Carried out duties independently or with minimum supervision in a cross-office environment with', 'project team members spanning multiple cities worldwide.']",8
36,//nb/corp/Users/NY/NY16/sbhardwa/@nbcfg/Desktop/Python codes/PDFextract/New folder/CV\Vikas_D-Hadoop-DE.pdf,0.97723937,cluster configur hadoop instal big data use cloudera hdf reduc engin hive hbase work creat servic level secur applic process kerbero provid involv support product mapr variou year lambda multipl capac plan manag mapreduc tabl autom hdp api ,"['aws{7}', 'docker{0},', 'sql{2}', 'hadoop{23}', 'hive{8}', 'teradata{0},', 'scala{1}', 'kubernetes{0},', 's3{3}', 'amazon redshift{0},', 'python{0},', 'matlab{0},', 'django{0},']",44,education is unknown,"['domain configuration.', '• On demand secure Amazon EMR launcher with custom spark submit steps using S3 Event, SNS,', 'KMS and Lambda function.', '• Extensive knowledge of working on NiFi.', '• Migrated an existing on-premises application to AWS.', '• Used AWS services like EC2 and S3 for small data sets.', '• Used Cloud watch logs to move application logs to S3 and create alarms based on a few', 'exceptions raised by applications.', '• Continuous coordination with QA team, production support team and deployment team.', '• Implemented test scripts to support test driven development and continuous integration.', '• Populated HDFS and Cassandra with huge amounts of data using Apache Kafka.', 'Hadoop Engineer at Phizer Pharmaceuticals Inc', 'March 2013 \xa0-\xa0 June 2016\xa0 (3 years 4 months)', '•Installed and configured Hadoop Map Reduce, HDFS, developed multiple Map Reduce jobs in java', 'for data cleaning and pre-processing.', '•Worked on Installing and configuring the HDP Hortonworks 2.x Clusters in Dev and Production', 'Environments.', '•Worked on Capacity planning for the Production Cluster.', '•Installed HUE Browser.', '•Involved in loading data from UNIX file system to HDFS and creating Hive tables, loading with data', 'and writing hive queries which will run internally in map reduce way.', '•Experience in MapR, Cloudera, & EMR Hadoop distributions.', '•Create a complete processing engine, based on Hortonworks distribution, enhanced to', 'performance.', '•Performed on cluster up gradation in Hadoop for cloudera.', '•Ability to Configuring queues in capacity scheduler and taking Snapshot backups for HBase', 'tables.', '•Worked on fixing the cluster issues and Configuring High Availability for Name Node in HDP 2.1.', '•Involved in Cluster Monitoring backup, restore and troubleshooting activities.', '•Currently working as Hadoop administrator in MapR hadoop distribution for 5 clusters ranges from', 'POC clusters to PROD clusters contains more than 1000 nodes.', '• Implemented manifest files in puppet for automated orchestration of Hadoop and Cassandra', 'clusters.', '•Worked on installing cluster, commissioning & decommissioning of Data Nodes, Name Node', 'recovery, capacity planning, Cassandra and slots configuration.', '•Administration of Hbase, Hive, Sqoop, HDFS, and MapR.', '•Importing and exporting data from different databases like MySQL, RDBMS into HDFS and', 'HBASE using Sqoop.', '•Worked on Configuring Kerberos Authentication in the cluster', 'Hadoop/Linux Admin at Microland Limited', 'January 2012 \xa0-\xa0 February 2013\xa0 (1 year 2 months)', '• Provide technical designs, architecture, Support automation, installation and configuration tasks', 'and upgrades and planning system upgrades of Hadoop cluster.', '• Design development and architecture of the Hadoop cluster, map reduce processes, Hbase', 'system.', '• Design and develop process framework and support data migration in Hadoop system.', '• Involved in installation and configuration of Kerberos security setup on CDH5.5 cluster.', '• Involved in upgrading Hadoop Cluster from HDP 1.3 to HDP 2.0.', '• Implemented secondary sorting to sort reducer output globally in MapReduce.', '• Involved in installation and configuration of LDAP server and integrated with kerberos on cluster.', '• Worked with Sentry configuration to provide centralized security to hadoop services.', '• Scheduled Oozie workflow engine to run multiple Hive and Pig jobs, which independently run with', 'time and data availability.', '• Work with network and Linux system engineers to define optimum network configurations, server', 'hardware and operating system.', '• Used Sqoop to import and export data from HDFS to RDBMS and vice-versa.', '• Created HBase tables to store various data formats of data coming from different portfolios.', '• Monitor critical services and provide on call support to the production team on various issues.', '• Assist in Install and configuration of Hive, Pig, Sqoop, Flume, Oozie and HBase on the Hadoop', 'cluster with latest patches.', '• Involved in performance tuning of various hadoop ecosystem components like YARN, MRv2.', '• Implemented the Kerberos security software to CDH cluster for user level as well as service level', 'to provide strong security to the cluster.', '• Troubleshooting, diagnosing, tuning, and solving Hadoop issues.', '• Continuous monitoring and managing the Hadoop cluster using Cloudera Manager.', 'Environment: Hortonworks (HDP 2.2), Ambari, Map Reduce 2.0(Yarn), HDFS, Hive, Hbase, Pig,', 'Oozie, Sqoop, Spark, Flume, Kerberos, Zookeeper, DB2, SQL Server 2014, CentOS, Linux, RHEL', '6.x, 7.x.', 'Vikas D.', 'Greater New York City Area', 'Big Data (Hadoop) Engineer']",Not Found
2,//nb/corp/Users/NY/NY16/sbhardwa/@nbcfg/Desktop/Python codes/PDFextract/New folder/CV\Anna_Smith.pdf,0.965012807,data engin year month use product custom tool creat intern code analyst test industri consumpt includ analysi user univers oregon june new improv quantum frequenc gener process spontan raman scatter ,"['aws{0},', 'docker{0},', 'sql{0},', 'hadoop{1}', 'hive{0},', 'teradata{0},', 'scala{0},', 'kubernetes{0},', 's3{0},', 'amazon redshift{0},', 'python{1}', 'matlab{0},', 'django{0},']",2,"['University of Oregon', 'M.Sc., partial Ph.D (ABD).,\xa0Physics,\xa02008\xa0-\xa02012', 'Activities and Societies:\xa0 GTFF, AFT', 'Seattle University', 'B.S.,\xa0Physics,\xa02004\xa0-\xa02008', 'Activities and Societies:\xa0 Society of Physics Students, Sigma Pi Sigma, Alpha Sigma Nu, Crew Team', 'Anna Smith', 'Greater New York City Area', 'Data Engineer at spotify']","['development and productization of a company priority audience analysis product that offers B2B', 'customers an unparalleled understanding and insight into their own user/consumer behavior.', 'Research Assistant at University of Oregon', 'June 2010 \xa0-\xa0 December 2012\xa0 (2 years 7 months)', 'Advisers: Drs. Stephen Hsu and James Schombert', 'Investigating techniques for dealing with large data sets, including machine learning and database']",2
22,//nb/corp/Users/NY/NY16/sbhardwa/@nbcfg/Desktop/Python codes/PDFextract/New folder/CV\Mrugesh_Patel_Hadoop-DE.pdf,0.948829446,hadoop data engin applic use load test file team experi requir set perform creat hive servic commun code jersey year technolog design script month busi support manag chang elast search methodolog softwar carrier configur send analyz shell sourc bank hdf hbase ,"['aws{5}', 'docker{0},', 'sql{2}', 'hadoop{13}', 'hive{7}', 'teradata{0},', 'scala{0},', 'kubernetes{0},', 's3{3}', 'amazon redshift{0},', 'python{2}', 'matlab{0},', 'django{0},']",32,"['New Jersey Institute of Technology', 'Masters of Science (MSc),\xa0Computer Science,\xa02014\xa0-\xa02015', 'Activities and Societies:\xa0 Volley Ball, Badminton, Cricket', 'New Jersey Institute of Technology', 'Bachelors of Science (BSc),\xa0Computer Science,\xa02010\xa0-\xa02014', 'Mrugesh Patel', 'Jersey City, New Jersey', 'Hadoop Data Engineer at Deutsche Bank']",[],Not Found
1,//nb/corp/Users/NY/NY16/sbhardwa/@nbcfg/Desktop/Python codes/PDFextract/New folder/CV\Alon_Honig.pdf,0.923938848,python manag senior data engin includ client use postgresql custom search cost file download experi applic excel test benefit tabl identifi strategi map framework relat databas model instrument optim corpor busi year month risk resourc carlo flask valid report trade research new person life provid product list insur repositori mysql taxonomi ,"['aws{0},', 'docker{0},', 'sql{16}', 'hadoop{1}', 'hive{2}', 'teradata{0},', 'scala{0},', 'kubernetes{0},', 's3{0},', 'amazon redshift{0},', 'python{8}', 'matlab{0},', 'django{0},']",27,"['University of Toronto', 'MA,\xa0Economics,\xa02010\xa0-\xa02011', 'Western University', 'BA,\xa0Financial Economics,\xa02006\xa0-\xa02010', 'Alon Honig', 'New York, New York', 'Senior Data Engineer at JUUL Labs']","['Modularized workflow by eliminating duplication, automating data mapping, and regularizing data', 'attributes. Enhanced functionality includes date customization, automated reconciliation and', 'improved dashboarding.']",Not Found
